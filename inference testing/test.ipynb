{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text: I want to cnacel order ord-2134\n",
      "Token | Predicted Tag | Probability\n",
      "I               | O               | 0.9995\n",
      "Ġwant           | O               | 0.9998\n",
      "Ġto             | O               | 0.9999\n",
      "Ġc              | O               | 0.9986\n",
      "n               | O               | 0.9986\n",
      "ac              | O               | 0.9994\n",
      "el              | O               | 0.9989\n",
      "Ġorder          | O               | 0.9998\n",
      "Ġord            | O               | 0.9996\n",
      "-               | O               | 0.9955\n",
      "2               | O               | 0.9986\n",
      "134             | O               | 0.9972\n",
      "\n",
      "Inference Results:\n",
      "Intent: delivery_options (Confidence: 0.1098)\n",
      "Category: order (Confidence: 0.3472)\n",
      "NER:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import GPT2TokenizerFast\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_inference(model_path: str, tokenizer_path: str, label_encoders_path: str, input_text: str, \n",
    "                  max_length: int = 128, debug: bool = True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the full model\n",
    "    model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    model.eval()\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = GPT2TokenizerFast.from_pretrained(tokenizer_path)\n",
    "\n",
    "    # Load label encoders\n",
    "    with open(label_encoders_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        label_encoders = json.load(f)\n",
    "    intent_decoder = {v: k for k, v in label_encoders[\"intent_encoder\"].items()}\n",
    "    category_decoder = {v: k for k, v in label_encoders[\"category_encoder\"].items()}\n",
    "    ner_decoder = {v: k for k, v in label_encoders[\"ner_label_encoder\"].items()}\n",
    "\n",
    "    # Preprocess input with offset mapping\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    offset_mapping = inputs[\"offset_mapping\"][0].cpu().tolist()\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        intent_logits = outputs[\"intent_logits\"]\n",
    "        category_logits = outputs[\"category_logits\"]\n",
    "        ner_logits = outputs[\"ner_logits\"][0]  # [seq_len, num_ner_labels]\n",
    "\n",
    "        # Intent prediction\n",
    "        intent_probs = F.softmax(intent_logits, dim=-1)[0]\n",
    "        intent_pred_idx = torch.argmax(intent_probs).item()\n",
    "        intent_confidence = intent_probs[intent_pred_idx].item()\n",
    "        intent_label = intent_decoder[intent_pred_idx]\n",
    "\n",
    "        # Category prediction\n",
    "        category_probs = F.softmax(category_logits, dim=-1)[0]\n",
    "        category_pred_idx = torch.argmax(category_probs).item()\n",
    "        category_confidence = category_probs[category_pred_idx].item()\n",
    "        category_label = category_decoder[category_pred_idx]\n",
    "\n",
    "        # NER prediction\n",
    "        ner_probs = F.softmax(ner_logits, dim=-1)\n",
    "        ner_pred_idxs = torch.argmax(ner_probs, dim=-1).tolist()\n",
    "        ner_confidences = torch.max(ner_probs, dim=-1).values.tolist()\n",
    "        ner_labels = [ner_decoder[idx] for idx in ner_pred_idxs]\n",
    "\n",
    "        # Truncate to sequence length\n",
    "        seq_len = inputs[\"attention_mask\"][0].sum().item()\n",
    "        ner_labels = ner_labels[:seq_len]\n",
    "        ner_confidences = ner_confidences[:seq_len]\n",
    "        offset_mapping = offset_mapping[:seq_len]\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][:seq_len].cpu().tolist())\n",
    "\n",
    "    # Debug raw predictions\n",
    "    if debug:\n",
    "        print(f\"\\nText: {input_text}\")\n",
    "        print(\"Token | Predicted Tag | Probability\")\n",
    "        for token, label, conf in zip(tokens, ner_labels, ner_confidences):\n",
    "            print(f\"{token:<15} | {label:<15} | {conf:.4f}\")\n",
    "\n",
    "    # Detect entity spans with subword handling\n",
    "    entities = []\n",
    "    current_entity = None\n",
    "    entity_start = None\n",
    "    entity_confidences = []\n",
    "    entity_text = \"\"\n",
    "\n",
    "    for i, (label, conf, (start, end), token) in enumerate(zip(ner_labels, ner_confidences, offset_mapping, tokens)):\n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_entity is not None:\n",
    "                entities.append({\n",
    "                    \"entity\": entity_text.strip(),\n",
    "                    \"label\": current_entity,\n",
    "                    \"confidence\": sum(entity_confidences) / len(entity_confidences)\n",
    "                })\n",
    "            current_entity = label[2:]\n",
    "            entity_start = start\n",
    "            entity_confidences = [conf]\n",
    "            entity_text = token if not token.startswith(\"##\") else token[2:]\n",
    "        elif label.startswith(\"I-\") and current_entity == label[2:]:\n",
    "            entity_confidences.append(conf)\n",
    "            if token.startswith(\"##\"):\n",
    "                entity_text += token[2:]  # Append subword without \"##\"\n",
    "            else:\n",
    "                entity_text += \" \" + token\n",
    "        elif label == \"O\" and current_entity is not None:\n",
    "            entities.append({\n",
    "                \"entity\": entity_text.strip(),\n",
    "                \"label\": current_entity,\n",
    "                \"confidence\": sum(entity_confidences) / len(entity_confidences)\n",
    "            })\n",
    "            current_entity = None\n",
    "            entity_confidences = []\n",
    "            entity_text = \"\"\n",
    "        elif label == \"O\":\n",
    "            current_entity = None\n",
    "            entity_confidences = []\n",
    "            entity_text = \"\"\n",
    "\n",
    "    if current_entity is not None:\n",
    "        entities.append({\n",
    "            \"entity\": entity_text.strip(),\n",
    "            \"label\": current_entity,\n",
    "            \"confidence\": sum(entity_confidences) / len(entity_confidences)\n",
    "        })\n",
    "\n",
    "    # Compile results\n",
    "    results = {\n",
    "        \"intent\": {\"label\": intent_label, \"confidence\": intent_confidence},\n",
    "        \"category\": {\"label\": category_label, \"confidence\": category_confidence},\n",
    "        \"ner\": entities\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"../results/baseline/test_2/model/full_model.pt\"\n",
    "    tokenizer_path = \"../results/baseline/test_2/tokenizer\"\n",
    "    label_encoders_path = \"../results/baseline/test_2/label_encoders.json\"\n",
    "    input_text = \"I want to cnacel order ord-2134\"\n",
    "\n",
    "    results = run_inference(model_path, tokenizer_path, label_encoders_path, input_text)\n",
    "    \n",
    "    print(\"\\nInference Results:\")\n",
    "    print(f\"Intent: {results['intent']['label']} (Confidence: {results['intent']['confidence']:.4f})\")\n",
    "    print(f\"Category: {results['category']['label']} (Confidence: {results['category']['confidence']:.4f})\")\n",
    "    print(\"NER:\")\n",
    "    for entity in results['ner']:\n",
    "        print(f\"  Entity: {entity['entity']} | Label: {entity['label']} | Confidence: {entity['confidence']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
