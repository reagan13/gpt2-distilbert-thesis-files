{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "gbKval_1PJak"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reagan13/gpt2-distilbert-thesis-files/blob/main/notebook/Hybrid_Model_WeightedSum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multitask Learning with Hybrid (GPT2-Distilbert)"
      ],
      "metadata": {
        "id": "WU5-iqe8XY46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "uDdgWxvqUIgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "from typing import List, Dict, Optional\n",
        "from collections import Counter, defaultdict\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    GPT2Model, GPT2Config, GPT2TokenizerFast,\n",
        "    DistilBertModel, DistilBertTokenizerFast,  # Added for DistilBERT\n",
        "    AdamW, get_linear_schedule_with_warmup\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score\n",
        "from datetime import datetime\n",
        "\n",
        "# Verify device and GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Selected device: {device}\")\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Initial GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    print(\"No GPU detected. Running on CPU.\")\n",
        "\n",
        "# Function to check device of tensors or models (retained)\n",
        "def check_device(item, name=\"Item\"):\n",
        "    if isinstance(item, torch.nn.Module):\n",
        "        param = next(item.parameters(), None)\n",
        "        if param is not None:\n",
        "            print(f\"{name} is on: {param.device}\")\n",
        "        else:\n",
        "            print(f\"{name} has no parameters to check\")\n",
        "    elif isinstance(item, torch.Tensor):\n",
        "        print(f\"{name} is on: {item.device}\")\n",
        "    else:\n",
        "        print(f\"{name} is not a tensor or model: {type(item)}\")\n",
        "\n",
        "def setup_logging(save_path: str, filename: str = \"training_log.txt\"):\n",
        "    try:\n",
        "        # Ensure local directory exists\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        local_log_path = os.path.join(save_path, filename)\n",
        "        print(f\"Local log path created: {local_log_path}\")\n",
        "\n",
        "        # Ensure Google Drive directory exists\n",
        "        drive_base_path = '/content/drive/'\n",
        "        if not os.path.exists(drive_base_path):\n",
        "            raise FileNotFoundError(\"Google Drive not mounted. Please mount it first.\")\n",
        "        drive_path = os.path.join(drive_base_path, save_path)\n",
        "        os.makedirs(drive_path, exist_ok=True)\n",
        "        drive_log_path = os.path.join(drive_path, filename)\n",
        "        print(f\"Google Drive log path created: {drive_log_path}\")\n",
        "\n",
        "        class Logger:\n",
        "            def __init__(self, local_path, drive_path):\n",
        "                # Open files in append mode with no buffering\n",
        "                self.local_file = open(local_path, \"a\", encoding=\"utf-8\", buffering=1)  # Line-buffered\n",
        "                self.drive_file = open(drive_path, \"a\", encoding=\"utf-8\", buffering=1)  # Line-buffered\n",
        "                self.original_stdout = sys.stdout\n",
        "\n",
        "            def write(self, message):\n",
        "                # Write to both files and original stdout\n",
        "                self.local_file.write(message)\n",
        "                self.drive_file.write(message)\n",
        "                self.original_stdout.write(message)\n",
        "                # Force flush to ensure immediate write\n",
        "                self.local_file.flush()\n",
        "                self.drive_file.flush()\n",
        "                self.original_stdout.flush()\n",
        "\n",
        "            def flush(self):\n",
        "                self.local_file.flush()\n",
        "                self.drive_file.flush()\n",
        "                self.original_stdout.flush()\n",
        "\n",
        "            def close(self):\n",
        "                self.local_file.close()\n",
        "                self.drive_file.close()\n",
        "                sys.stdout = self.original_stdout\n",
        "\n",
        "        # Instantiate logger and redirect stdout\n",
        "        logger = Logger(local_log_path, drive_log_path)\n",
        "        sys.stdout = logger\n",
        "\n",
        "        # Initial log messages\n",
        "        print(f\"Logging started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        print(f\"Log file: {local_log_path}\")\n",
        "        print(f\"Drive log file: {drive_log_path}\")\n",
        "\n",
        "        return logger  # Return logger for manual control if needed\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up logging: {e}\", file=sys.__stdout__)  # Log to original stdout on error\n",
        "        sys.stdout = sys.__stdout__  # Reset stdout on failure\n",
        "        return None\n",
        "\n",
        "\n",
        "print(f\"Current date: {datetime.now().strftime('%B %d, %Y')}\")"
      ],
      "metadata": {
        "id": "CKCve4yhUHS6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dasaet Loading Functions"
      ],
      "metadata": {
        "id": "G9xMYvhFUMeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(json_file: str) -> List[Dict]:\n",
        "    \"\"\"Load dataset from a JSON file.\"\"\"\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def detect_labels(data: List[Dict]) -> Dict[str, Dict]:\n",
        "    \"\"\"Detect unique labels and create encoders for categories, intents, and NER tags.\"\"\"\n",
        "    start_time = time.time()\n",
        "    if not isinstance(data, list):\n",
        "        raise TypeError(\"Input 'data' must be a list of dictionaries\")\n",
        "    if not data:\n",
        "        return {\"category_encoder\": {}, \"intent_encoder\": {}, \"ner_label_encoder\": {\"O\": 0}}\n",
        "\n",
        "    unique_categories = set()\n",
        "    unique_intents = set()\n",
        "    unique_ner_labels = set([\"O\"])\n",
        "    missing_fields = defaultdict(int)\n",
        "    category_counts = Counter()\n",
        "    intent_counts = Counter()\n",
        "    ner_counts = Counter()\n",
        "\n",
        "    for i, sample in enumerate(data):\n",
        "        try:\n",
        "            category = sample[\"category\"]\n",
        "            intent = sample[\"intent\"]\n",
        "            unique_categories.add(category)\n",
        "            unique_intents.add(intent)\n",
        "            category_counts[category] += 1\n",
        "            intent_counts[intent] += 1\n",
        "\n",
        "            ner_labels = sample[\"ner_labels_only\"]\n",
        "            if not isinstance(ner_labels, list):\n",
        "                raise ValueError(f\"'ner_labels_only' must be a list at sample {i}\")\n",
        "            for label in ner_labels:\n",
        "                if not isinstance(label, dict) or \"label\" not in label or \"text\" not in label:\n",
        "                    raise ValueError(f\"NER label must have 'label' and 'text' fields at sample {i}\")\n",
        "                label_type = label[\"label\"]\n",
        "                unique_ner_labels.add(f\"B-{label_type}\")\n",
        "                unique_ner_labels.add(f\"I-{label_type}\")\n",
        "                ner_counts[f\"B-{label_type}\"] += 1\n",
        "                ner_counts[f\"I-{label_type}\"] += 1\n",
        "        except KeyError as e:\n",
        "            missing_fields[str(e).strip(\"'\")] += 1\n",
        "            continue\n",
        "\n",
        "    if missing_fields:\n",
        "        print(\"Warning: Missing fields detected:\")\n",
        "        for field, count in missing_fields.items():\n",
        "            print(f\"  - '{field}' missing in {count} samples\")\n",
        "\n",
        "    category_encoder = {cat: idx for idx, cat in enumerate(sorted(unique_categories))}\n",
        "    intent_encoder = {intent: idx for idx, intent in enumerate(sorted(unique_intents))}\n",
        "    ner_label_encoder = {ner: idx for idx, ner in enumerate(sorted(unique_ner_labels))}\n",
        "\n",
        "    print(f\"Dataset summary:\\n  - {len(data)} samples\\n  - {len(category_encoder)} categories\\n  - {len(intent_encoder)} intents\\n  - {len(ner_label_encoder)} NER tags\")\n",
        "    print(\"Category distribution:\", dict(category_counts))\n",
        "    print(\"Intent distribution:\", dict(intent_counts))\n",
        "    print(\"NER tag distribution (non-O):\", dict(ner_counts))\n",
        "    print(f\"Processing time: {time.time() - start_time:.3f} seconds\")\n",
        "\n",
        "    return {\"category_encoder\": category_encoder, \"intent_encoder\": intent_encoder, \"ner_label_encoder\": ner_label_encoder}"
      ],
      "metadata": {
        "id": "NQhYy09xUPAX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and NER Alignment"
      ],
      "metadata": {
        "id": "ZSJYDchMUT20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text_hybrid(text: str, gpt2_tokenizer, distilbert_tokenizer, max_length: int) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Tokenize text using both GPT-2 and DistilBERT tokenizers.\"\"\"\n",
        "    gpt2_inputs = gpt2_tokenizer(\n",
        "        text, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    distilbert_inputs = distilbert_tokenizer(\n",
        "        text, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    return {\n",
        "        \"gpt2_input_ids\": gpt2_inputs[\"input_ids\"].squeeze(0),\n",
        "        \"gpt2_attention_mask\": gpt2_inputs[\"attention_mask\"].squeeze(0),\n",
        "        \"distilbert_input_ids\": distilbert_inputs[\"input_ids\"].squeeze(0),\n",
        "        \"distilbert_attention_mask\": distilbert_inputs[\"attention_mask\"].squeeze(0)\n",
        "    }\n",
        "\n",
        "def align_ner_labels(text: str, ner_labels: List[Dict], tokenizer, ner_label_encoder: Dict, max_length: int) -> torch.Tensor:\n",
        "    \"\"\"Align NER labels with tokenized input (using GPT-2 tokenizer for consistency).\"\"\"\n",
        "    sorted_labels = sorted(ner_labels, key=lambda x: len(x[\"text\"]), reverse=True) if ner_labels else []\n",
        "    encoding = tokenizer(\n",
        "        text, max_length=max_length, padding=\"max_length\", truncation=True, return_offsets_mapping=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    token_to_char_map = encoding[\"offset_mapping\"][0].tolist()\n",
        "    ner_aligned = [ner_label_encoder[\"O\"]] * max_length\n",
        "\n",
        "    for label in sorted_labels:\n",
        "        if \"text\" not in label or \"label\" not in label:\n",
        "            print(f\"Warning: Skipping invalid NER entry {label} (missing 'text' or 'label')\")\n",
        "            continue\n",
        "        try:\n",
        "            label_text, label_type = label[\"text\"], label[\"label\"]\n",
        "            start_pos = 0\n",
        "            while True:\n",
        "                label_start = text.find(label_text, start_pos)\n",
        "                if label_start == -1:\n",
        "                    break\n",
        "                label_end = label_start + len(label_text)\n",
        "                start_pos = label_end\n",
        "                first_token = True\n",
        "                for i, (start, end) in enumerate(token_to_char_map):\n",
        "                    if start == 0 and end == 0:\n",
        "                        continue\n",
        "                    if max(start, label_start) < min(end, label_end):\n",
        "                        prefix = \"B-\" if first_token else \"I-\"\n",
        "                        first_token = False\n",
        "                        ner_aligned[i] = ner_label_encoder.get(f\"{prefix}{label_type}\", ner_label_encoder[\"O\"])\n",
        "        except KeyError as e:\n",
        "            print(f\"Warning: Label '{e}' not found in encoder. Skipping.\")\n",
        "\n",
        "    return torch.tensor(ner_aligned, dtype=torch.long)"
      ],
      "metadata": {
        "id": "9kMHmK7lUZUG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and Dataloader"
      ],
      "metadata": {
        "id": "ee_1s8_LUb-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, data: List[Dict], gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length: int):\n",
        "        self.data = data\n",
        "        self.gpt2_tokenizer = gpt2_tokenizer\n",
        "        self.distilbert_tokenizer = distilbert_tokenizer\n",
        "        self.label_encoders = label_encoders\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        text = sample[\"instruction\"]\n",
        "         # Tokenize with GPT-2\n",
        "        gpt2_inputs = self.gpt2_tokenizer(\n",
        "            text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt'\n",
        "        )\n",
        "        # Tokenize with DistilBERT\n",
        "        distilbert_inputs = self.distilbert_tokenizer(\n",
        "            text, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Align NER labels with GPT-2 tokenization (consistent with baseline)\n",
        "        ner_labels = align_ner_labels(text, sample[\"ner_labels_only\"], self.gpt2_tokenizer,\n",
        "                                     self.label_encoders[\"ner_label_encoder\"], self.max_length)\n",
        "        return {\n",
        "            \"gpt2_input_ids\": gpt2_inputs['input_ids'].squeeze(0),\n",
        "            \"gpt2_attention_mask\": gpt2_inputs['attention_mask'].squeeze(0),\n",
        "            \"distilbert_input_ids\": distilbert_inputs['input_ids'].squeeze(0),\n",
        "            \"distilbert_attention_mask\": distilbert_inputs['attention_mask'].squeeze(0),\n",
        "            \"category_labels\": torch.tensor(self.label_encoders[\"category_encoder\"][sample[\"category\"]], dtype=torch.long),\n",
        "            \"intent_labels\": torch.tensor(self.label_encoders[\"intent_encoder\"][sample[\"intent\"]], dtype=torch.long),\n",
        "            \"ner_labels\": ner_labels\n",
        "        }\n",
        "\n",
        "def get_dataloaders(train_data, val_data, test_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, batch_size, num_workers, max_length):\n",
        "    \"\"\"Create DataLoaders for train, validation, and test sets.\"\"\"\n",
        "    pin_memory = device.type == \"cuda\"\n",
        "    train_dataset = MultiTaskDataset(train_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length)\n",
        "    val_dataset = MultiTaskDataset(val_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length)\n",
        "    test_dataset = MultiTaskDataset(test_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length)\n",
        "\n",
        "    return (\n",
        "        DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "    )"
      ],
      "metadata": {
        "id": "wYt1cv-1UePb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "8_kvjRnHUfo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttentionFusionLayer(nn.Module):\n",
        "    def __init__(self, gpt2_dim: int, bert_dim: int, output_dim: int, dropout_rate: float, num_heads: int = 8):\n",
        "        super().__init__()\n",
        "        self.gpt2_proj = nn.Linear(gpt2_dim, output_dim)\n",
        "        self.bert_proj = nn.Linear(bert_dim, output_dim)\n",
        "        self.cross_attention = nn.MultiheadAttention(embed_dim=output_dim, num_heads=num_heads, dropout=dropout_rate, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_norm = nn.LayerNorm(output_dim)\n",
        "\n",
        "    def forward(self, gpt2_features: torch.Tensor, bert_features: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        gpt2_proj = self.gpt2_proj(gpt2_features)  # [batch_size, seq_len, output_dim]\n",
        "        bert_proj = self.bert_proj(bert_features)  # [batch_size, seq_len, output_dim]\n",
        "        attn_mask = attention_mask.float().masked_fill(attention_mask == 0, float('-inf')).masked_fill(attention_mask == 1, 0)\n",
        "        fused_features, _ = self.cross_attention(\n",
        "            query=gpt2_proj,\n",
        "            key=bert_proj,\n",
        "            value=bert_proj,\n",
        "            key_padding_mask=attention_mask == 0\n",
        "        )\n",
        "        fused_features = self.dropout(fused_features) + gpt2_proj  # Residual connection\n",
        "        return self.layer_norm(fused_features)\n",
        "\n",
        "class HybridGPT2DistilBERTMultiTask(nn.Module):\n",
        "    def __init__(self, num_intents: int, num_categories: int, num_ner_labels: int, dropout_rate: float):\n",
        "        super().__init__()\n",
        "        self.gpt2_config = GPT2Config.from_pretrained('gpt2')\n",
        "        self.gpt2 = GPT2Model.from_pretrained('gpt2')\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "        for param in self.gpt2.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.distilbert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        gpt2_dim = self.gpt2_config.n_embd\n",
        "        bert_dim = self.distilbert.config.hidden_size\n",
        "        hidden_size = gpt2_dim  # Keeping output dim same as GPT-2 for consistency\n",
        "\n",
        "        self.fusion_layer = CrossAttentionFusionLayer(gpt2_dim, bert_dim, hidden_size, dropout_rate)\n",
        "\n",
        "        self.intent_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, num_intents)\n",
        "        )\n",
        "        self.category_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, num_categories)\n",
        "        )\n",
        "        self.ner_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, num_ner_labels)\n",
        "        )\n",
        "\n",
        "        self.intent_loss_fn = nn.CrossEntropyLoss()\n",
        "        self.category_loss_fn = nn.CrossEntropyLoss()\n",
        "        self.ner_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, gpt2_input_ids: torch.Tensor, gpt2_attention_mask: torch.Tensor,\n",
        "                distilbert_input_ids: torch.Tensor, distilbert_attention_mask: torch.Tensor,\n",
        "                intent_labels: Optional[torch.Tensor] = None,\n",
        "                category_labels: Optional[torch.Tensor] = None,\n",
        "                ner_labels: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        gpt2_outputs = self.gpt2(input_ids=gpt2_input_ids, attention_mask=gpt2_attention_mask)\n",
        "        distilbert_outputs = self.distilbert(input_ids=distilbert_input_ids, attention_mask=distilbert_attention_mask)\n",
        "\n",
        "        gpt2_features = gpt2_outputs.last_hidden_state\n",
        "        bert_features = distilbert_outputs.last_hidden_state\n",
        "\n",
        "        fused_features = self.fusion_layer(gpt2_features, bert_features, gpt2_attention_mask)\n",
        "\n",
        "        batch_size = fused_features.shape[0]\n",
        "        sequence_lengths = gpt2_attention_mask.sum(dim=1) - 1\n",
        "        last_token_indexes = sequence_lengths.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, fused_features.shape[-1])\n",
        "        sequence_repr = torch.gather(fused_features, 1, last_token_indexes).squeeze(1)\n",
        "\n",
        "        intent_logits = self.intent_head(sequence_repr)\n",
        "        category_logits = self.category_head(sequence_repr)\n",
        "        ner_logits = self.ner_head(fused_features)\n",
        "\n",
        "        output_dict = {\n",
        "            'intent_logits': intent_logits,\n",
        "            'category_logits': category_logits,\n",
        "            'ner_logits': ner_logits\n",
        "        }\n",
        "\n",
        "        if all(label is not None for label in [intent_labels, category_labels, ner_labels]):\n",
        "            intent_loss = self.intent_loss_fn(intent_logits, intent_labels)\n",
        "            category_loss = self.category_loss_fn(category_logits, category_labels)\n",
        "            active_loss = gpt2_attention_mask.view(-1) == 1\n",
        "            active_logits = ner_logits.view(-1, ner_logits.size(-1))[active_loss]\n",
        "            active_labels = ner_labels.view(-1)[active_loss]\n",
        "            ner_loss = self.ner_loss_fn(active_logits, active_labels)\n",
        "\n",
        "            output_dict.update({\n",
        "                'loss': intent_loss + category_loss + ner_loss,\n",
        "                'intent_loss': intent_loss,\n",
        "                'category_loss': category_loss,\n",
        "                'ner_loss': ner_loss\n",
        "            })\n",
        "\n",
        "        return output_dict"
      ],
      "metadata": {
        "id": "SQeWYh9uUg7k"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "DEhnmgZNUkU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, learning_rate):\n",
        "    \"\"\"Train the multi-task model.\"\"\"\n",
        "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
        "    history = {\n",
        "        \"train_loss\": [], \"val_loss\": [],\n",
        "        \"train_intent_acc\": [], \"val_intent_acc\": [],\n",
        "        \"train_category_f1\": [], \"val_category_f1\": [],\n",
        "        \"train_ner_f1\": [], \"val_ner_f1\": []\n",
        "    }\n",
        "\n",
        "    model.to(device)\n",
        "    check_device(model, \"Model\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        all_train_intent_preds, all_train_intent_labels = [], []\n",
        "        all_train_category_preds, all_train_category_labels = [], []\n",
        "        all_train_ner_preds, all_train_ner_labels = [], []\n",
        "\n",
        "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False) as train_loop:\n",
        "            for i, batch in enumerate(train_loop):\n",
        "                optimizer.zero_grad()\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "                outputs = model(**inputs)\n",
        "                loss = outputs[\"loss\"]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "                intent_preds = torch.argmax(outputs[\"intent_logits\"], dim=-1).cpu().numpy()\n",
        "                category_preds = torch.argmax(outputs[\"category_logits\"], dim=-1).cpu().numpy()\n",
        "                ner_preds = torch.argmax(outputs[\"ner_logits\"], dim=-1).cpu().numpy()\n",
        "\n",
        "                all_train_intent_preds.extend(intent_preds)\n",
        "                all_train_intent_labels.extend(batch[\"intent_labels\"].cpu().numpy())\n",
        "                all_train_category_preds.extend(category_preds)\n",
        "                all_train_category_labels.extend(batch[\"category_labels\"].cpu().numpy())\n",
        "                all_train_ner_preds.extend(ner_preds.flatten())\n",
        "                all_train_ner_labels.extend(batch[\"ner_labels\"].cpu().numpy().flatten())\n",
        "\n",
        "        train_intent_acc = accuracy_score(all_train_intent_labels, all_train_intent_preds)\n",
        "        train_category_f1 = precision_recall_fscore_support(all_train_category_labels, all_train_category_preds, average=\"macro\", zero_division=0)[2]\n",
        "        train_ner_f1 = precision_recall_fscore_support(all_train_ner_labels, all_train_ner_preds, average=\"macro\", zero_division=0)[2]\n",
        "\n",
        "        history[\"train_loss\"].append(total_loss / len(train_loader))\n",
        "        history[\"train_intent_acc\"].append(train_intent_acc)\n",
        "        history[\"train_category_f1\"].append(train_category_f1)\n",
        "        history[\"train_ner_f1\"].append(train_ner_f1)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_val_intent_preds, all_val_intent_labels = [], []\n",
        "        all_val_category_preds, all_val_category_labels = [], []\n",
        "        all_val_ner_preds, all_val_ner_labels = [], []\n",
        "\n",
        "        val_loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loop:\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "                outputs = model(**inputs)\n",
        "                batch_val_loss = outputs[\"loss\"].item()\n",
        "                val_loss += batch_val_loss\n",
        "                val_loop.set_postfix(loss=batch_val_loss)\n",
        "\n",
        "                intent_preds = torch.argmax(outputs[\"intent_logits\"], dim=-1).cpu().numpy()\n",
        "                category_preds = torch.argmax(outputs[\"category_logits\"], dim=-1).cpu().numpy()\n",
        "                ner_preds = torch.argmax(outputs[\"ner_logits\"], dim=-1).cpu().numpy()\n",
        "\n",
        "                all_val_intent_preds.extend(intent_preds)\n",
        "                all_val_intent_labels.extend(batch[\"intent_labels\"].cpu().numpy())\n",
        "                all_val_category_preds.extend(category_preds)\n",
        "                all_val_category_labels.extend(batch[\"category_labels\"].cpu().numpy())\n",
        "                all_val_ner_preds.extend(ner_preds.flatten())\n",
        "                all_val_ner_labels.extend(batch[\"ner_labels\"].cpu().numpy().flatten())\n",
        "\n",
        "        val_intent_acc = accuracy_score(all_val_intent_labels, all_val_intent_preds)\n",
        "        val_category_f1 = precision_recall_fscore_support(all_val_category_labels, all_val_category_preds, average=\"macro\", zero_division=0)[2]\n",
        "        val_ner_f1 = precision_recall_fscore_support(all_val_ner_labels, all_val_ner_preds, average=\"macro\", zero_division=0)[2]\n",
        "\n",
        "        history[\"val_loss\"].append(val_loss / len(val_loader))\n",
        "        history[\"val_intent_acc\"].append(val_intent_acc)\n",
        "        history[\"val_category_f1\"].append(val_category_f1)\n",
        "        history[\"val_ner_f1\"].append(val_ner_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "        print(f\"  Train Loss:      {history['train_loss'][-1]:.4f}\")\n",
        "        print(f\"  Val Loss:       {history['val_loss'][-1]:.4f}\\n\")\n",
        "        print(f\"  Train Intent Acc: {train_intent_acc:.4f}\")\n",
        "        print(f\"  Val Intent Acc:  {val_intent_acc:.4f}\\n\")\n",
        "        print(f\"  Train Category F1:{train_category_f1:.4f}\")\n",
        "        print(f\"  Val Category F1: {val_category_f1:.4f}\\n\")\n",
        "        print(f\"  Train NER F1:     {train_ner_f1:.4f}\")\n",
        "        print(f\"  Val NER F1:      {val_ner_f1:.4f}\\n\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "rN3W8kTDUlTz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "r_W1hO4EUmly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    \"\"\"Evaluate the model on the test set.\"\"\"\n",
        "    model.eval()\n",
        "    all_intent_preds, all_intent_labels = [], []\n",
        "    all_category_preds, all_category_labels = [], []\n",
        "    all_ner_preds, all_ner_labels = [], []\n",
        "    total_loss = 0\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    test_loop = tqdm(test_loader, desc=\"Evaluation\", leave=True)\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loop:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**inputs)\n",
        "            batch_loss = outputs[\"loss\"].item()\n",
        "            total_loss += batch_loss\n",
        "            test_loop.set_postfix(loss=batch_loss)\n",
        "\n",
        "            intent_preds = torch.argmax(outputs[\"intent_logits\"], dim=-1).cpu().numpy()\n",
        "            category_preds = torch.argmax(outputs[\"category_logits\"], dim=-1).cpu().numpy()\n",
        "            ner_preds = torch.argmax(outputs[\"ner_logits\"], dim=-1).cpu().numpy()\n",
        "\n",
        "            all_intent_preds.extend(intent_preds)\n",
        "            all_intent_labels.extend(batch[\"intent_labels\"].cpu().numpy())\n",
        "            all_category_preds.extend(category_preds)\n",
        "            all_category_labels.extend(batch[\"category_labels\"].cpu().numpy())\n",
        "            all_ner_preds.extend(ner_preds.flatten())\n",
        "            all_ner_labels.extend(batch[\"ner_labels\"].cpu().numpy().flatten())\n",
        "\n",
        "    intent_acc = accuracy_score(all_intent_labels, all_intent_preds)\n",
        "    category_f1 = precision_recall_fscore_support(all_category_labels, all_category_preds, average=\"macro\", zero_division=0)[2]\n",
        "    ner_f1 = precision_recall_fscore_support(all_ner_labels, all_ner_preds, average=\"macro\", zero_division=0)[2]\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "    results = {\n",
        "        \"loss\": avg_loss,\n",
        "        \"intent_accuracy\": intent_acc,\n",
        "        \"category_f1\": category_f1,\n",
        "        \"ner_f1\": ner_f1\n",
        "    }\n",
        "\n",
        "    print(f\"Test Results:\")\n",
        "    print(f\"  Loss:            {avg_loss:.4f}\")\n",
        "    print(f\"  Intent Acc:      {intent_acc:.4f}\")\n",
        "    print(f\"  Category F1:     {category_f1:.4f}\")\n",
        "    print(f\"  NER F1:          {ner_f1:.4f}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "GvXcNp4vUoWC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Artifacts"
      ],
      "metadata": {
        "id": "3TL8MuAeUrFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Locally"
      ],
      "metadata": {
        "id": "Z1zKgwNB84OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_artifacts(label_encoders, metrics, test_results, save_path):\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    label_encoders_path = os.path.join(save_path, \"label_encoders.json\")\n",
        "    with open(label_encoders_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(label_encoders, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Label encoders saved to {label_encoders_path}\")\n",
        "\n",
        "    training_metrics_path = os.path.join(save_path, \"training_metrics.json\")\n",
        "    with open(training_metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Training metrics saved to {training_metrics_path}\")\n",
        "\n",
        "    test_results_path = os.path.join(save_path, \"test_results.json\")\n",
        "    with open(test_results_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(test_results, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Test results saved to {test_results_path}\")\n",
        "\n",
        "def save_training_config(config, save_path, filename=\"training_config.json\"):\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    config_path = os.path.join(save_path, filename)\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Training configuration saved to {config_path}\")\n",
        "\n",
        "def save_full_model(model, gpt2_tokenizer, distilbert_tokenizer, save_path):\n",
        "    model_path = os.path.join(save_path, \"model\")\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "    model_file_path = os.path.join(model_path, \"full_model.pt\")\n",
        "    torch.save(model, model_file_path)\n",
        "    print(f\"Full model saved to {model_file_path}\")\n",
        "\n",
        "    gpt2_tokenizer_path = os.path.join(save_path, \"gpt2_tokenizer\")\n",
        "    gpt2_tokenizer.save_pretrained(gpt2_tokenizer_path)\n",
        "    print(f\"GPT-2 tokenizer saved to {gpt2_tokenizer_path}\")\n",
        "\n",
        "    distilbert_tokenizer_path = os.path.join(save_path, \"distilbert_tokenizer\")\n",
        "    distilbert_tokenizer.save_pretrained(distilbert_tokenizer_path)\n",
        "    print(f\"DistilBERT tokenizer saved to {distilbert_tokenizer_path}\")\n"
      ],
      "metadata": {
        "id": "NTNnt-hVUsle"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save to GDrive"
      ],
      "metadata": {
        "id": "kRTW48OJ87HQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Execution"
      ],
      "metadata": {
        "id": "D_mQwQdBU4QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "def mount_drive():\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "\n",
        "def save_training_config_to_drive(config, drive_path, filename=\"training_config.json\"):\n",
        "    os.makedirs(\"/content/drive/\" + drive_path, exist_ok=True)\n",
        "    config_path = os.path.join(\"/content/drive/\", drive_path, filename)\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Training configuration saved to {config_path}\")\n",
        "\n",
        "def save_artifacts_to_drive(label_encoders, metrics, test_results, drive_path):\n",
        "    os.makedirs(\"/content/drive/\" + drive_path, exist_ok=True)\n",
        "    label_encoders_path = os.path.join(\"/content/drive/\", drive_path, \"label_encoders.json\")\n",
        "    with open(label_encoders_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(label_encoders, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Label encoders saved to {label_encoders_path}\")\n",
        "\n",
        "    training_metrics_path = os.path.join(\"/content/drive/\", drive_path, \"training_metrics.json\")\n",
        "    with open(training_metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Training metrics saved to {training_metrics_path}\")\n",
        "\n",
        "    test_results_path = os.path.join(\"/content/drive/\", drive_path, \"test_results.json\")\n",
        "    with open(test_results_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(test_results, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Test results saved to {test_results_path}\")\n",
        "\n",
        "def save_full_model_to_drive(model, gpt2_tokenizer, distilbert_tokenizer, drive_path):\n",
        "    model_path = os.path.join(\"/content/drive/\", drive_path, \"model\")\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "    model_file_path = os.path.join(model_path, \"full_model.pt\")\n",
        "    torch.save(model, model_file_path)\n",
        "    print(f\"Full model saved to {model_file_path}\")\n",
        "\n",
        "    gpt2_tokenizer_path = os.path.join(\"/content/drive/\", drive_path, \"gpt2_tokenizer\")\n",
        "    gpt2_tokenizer.save_pretrained(gpt2_tokenizer_path)\n",
        "    print(f\"GPT-2 tokenizer saved to {gpt2_tokenizer_path}\")\n",
        "\n",
        "    distilbert_tokenizer_path = os.path.join(\"/content/drive/\", drive_path, \"distilbert_tokenizer\")\n",
        "    distilbert_tokenizer.save_pretrained(distilbert_tokenizer_path)\n",
        "    print(f\"DistilBERT tokenizer saved to {distilbert_tokenizer_path}\")"
      ],
      "metadata": {
        "id": "lmb2KQ9y8-GB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paths and Hyperparameters"
      ],
      "metadata": {
        "id": "7v48SU_2U6DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths and Hyperparameters\n",
        "train_file = \"train.json\"\n",
        "val_file = \"val.json\"\n",
        "test_file = \"test.json\"\n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "learning_rate = 2e-5\n",
        "max_length = 128\n",
        "num_workers = 2\n",
        "save_path = \"MyDrive/thesis/hybrid_cross_attention/test_1\"\n",
        "dropout_rate = 0.2\n",
        "\n",
        "training_config = {\n",
        "    \"train_file\": train_file,\n",
        "    \"val_file\": val_file,\n",
        "    \"test_file\": test_file,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"num_epochs\": num_epochs,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"max_length\": max_length,\n",
        "    \"num_workers\": num_workers,\n",
        "    \"model_name\": \"HybridGPT2DistilBERTMultiTask\",\n",
        "    \"gpt2_base\": \"gpt2\",\n",
        "    \"distilbert_base\": \"distilbert-base-uncased\",\n",
        "    \"dropout_rate\": dropout_rate,\n",
        "    \"device\": str(device),\n",
        "    \"date\": datetime.now().strftime('%B %d, %Y')\n",
        "}\n"
      ],
      "metadata": {
        "id": "CiubTK2NU5h3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "-pIstRkZU-Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "mount_drive()\n",
        "# Setup logging and keep logger in scope\n",
        "logger = setup_logging(save_path)\n",
        "if logger is None:\n",
        "    raise RuntimeError(\"Logging setup failed. Check Google Drive mount and permissions.\")\n",
        "\n",
        "\n",
        "# Load datasets\n",
        "print(\"Loading datasets...\\n\")\n",
        "train_data = load_dataset(train_file)\n",
        "val_data = load_dataset(val_file)\n",
        "test_data = load_dataset(test_file)\n",
        "\n",
        "print(\"*\" * 30)\n",
        "print(f\"\"\"Dataset Summary:\n",
        "Training samples: {len(train_data)}\n",
        "Validation samples: {len(val_data)}\n",
        "Test samples: {len(test_data)}\"\"\")\n",
        "\n",
        "# Detect labels\n",
        "label_encoders = detect_labels(train_data)\n",
        "\n",
        "# Initialize tokenizers\n",
        "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
        "if gpt2_tokenizer.pad_token is None:\n",
        "    gpt2_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "distilbert_tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Create data loaders\n",
        "train_loader, val_loader, test_loader = get_dataloaders(\n",
        "    train_data, val_data, test_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, batch_size, num_workers, max_length\n",
        ")\n",
        "\n",
        "# Initialize model\n",
        "model = HybridGPT2DistilBERTMultiTask(\n",
        "    num_intents=len(label_encoders[\"intent_encoder\"]),\n",
        "    num_categories=len(label_encoders[\"category_encoder\"]),\n",
        "    num_ner_labels=len(label_encoders[\"ner_label_encoder\"]),\n",
        "    dropout_rate=dropout_rate\n",
        ")\n",
        "if gpt2_tokenizer.pad_token_id is not None:\n",
        "    model.gpt2.resize_token_embeddings(len(gpt2_tokenizer))\n",
        "\n",
        "model.to(device)\n",
        "check_device(model, \"Model before training\")\n",
        "\n",
        "# Save training config\n",
        "save_training_config(training_config, save_path)\n",
        "\n",
        "# Train model\n",
        "print(\"*\" * 30)\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "metrics = train_model(model, train_loader, val_loader, num_epochs, learning_rate)\n",
        "print(f\"Training completed in {(time.time() - start_time) / 60:.2f} minutes\")\n",
        "print(\"*\" * 30)\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Evaluating on test set...\")\n",
        "test_results = evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "gt_Gsk_LVAZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7f00091e-b8fc-476a-bb58-58c68710ebeb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e2568f73c24e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training completed in {(time.time() - start_time) / 60:.2f} minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-20e08d440a64>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the Artifacts(models, labels, tokenizer, etc)"
      ],
      "metadata": {
        "id": "XrjIlbTu9arS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save artifacts\n",
        "save_training_config(training_config, save_path)\n",
        "save_training_config_to_drive(training_config, save_path)\n",
        "save_artifacts(label_encoders, metrics, test_results, save_path)\n",
        "save_artifacts_to_drive(label_encoders, metrics, test_results, save_path)\n",
        "save_full_model(model, gpt2_tokenizer, distilbert_tokenizer, save_path)\n",
        "save_full_model_to_drive(model, gpt2_tokenizer, distilbert_tokenizer, save_path)"
      ],
      "metadata": {
        "id": "08otnCw79aPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vtk0XcBM9aHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "HC49miQf0RrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def run_inference(model_path: str, gpt2_tokenizer_path: str, distilbert_tokenizer_path: str, label_encoders_path: str, input_text: str, max_length: int = 128):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load the full model\n",
        "    model = torch.load(model_path, map_location=device, weights_only=False)\n",
        "    model.eval()\n",
        "\n",
        "    # Load tokenizers\n",
        "    gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(gpt2_tokenizer_path)\n",
        "    distilbert_tokenizer = DistilBertTokenizerFast.from_pretrained(distilbert_tokenizer_path)\n",
        "\n",
        "    # Load label encoders\n",
        "    with open(label_encoders_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        label_encoders = json.load(f)\n",
        "    intent_decoder = {v: k for k, v in label_encoders[\"intent_encoder\"].items()}\n",
        "    category_decoder = {v: k for k, v in label_encoders[\"category_encoder\"].items()}\n",
        "    ner_decoder = {v: k for k, v in label_encoders[\"ner_label_encoder\"].items()}\n",
        "\n",
        "    # Preprocess input\n",
        "    gpt2_inputs = gpt2_tokenizer(\n",
        "        input_text, return_tensors=\"pt\", max_length=max_length, padding=\"max_length\", truncation=True, return_offsets_mapping=True\n",
        "    )\n",
        "    distilbert_inputs = distilbert_tokenizer(\n",
        "        input_text, return_tensors=\"pt\", max_length=max_length, padding=\"max_length\", truncation=True\n",
        "    )\n",
        "    inputs = {\n",
        "        \"gpt2_input_ids\": gpt2_inputs[\"input_ids\"].to(device),\n",
        "        \"gpt2_attention_mask\": gpt2_inputs[\"attention_mask\"].to(device),\n",
        "        \"distilbert_input_ids\": distilbert_inputs[\"input_ids\"].to(device),\n",
        "        \"distilbert_attention_mask\": distilbert_inputs[\"attention_mask\"].to(device)\n",
        "    }\n",
        "    offset_mapping = gpt2_inputs[\"offset_mapping\"][0].cpu().tolist()\n",
        "\n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        intent_logits = outputs[\"intent_logits\"]\n",
        "        intent_probs = F.softmax(intent_logits, dim=-1)[0]\n",
        "        intent_pred_idx = torch.argmax(intent_probs).item()\n",
        "        intent_confidence = intent_probs[intent_pred_idx].item()\n",
        "        intent_label = intent_decoder[intent_pred_idx]\n",
        "\n",
        "        category_logits = outputs[\"category_logits\"]\n",
        "        category_probs = F.softmax(category_logits, dim=-1)[0]\n",
        "        category_pred_idx = torch.argmax(category_probs).item()\n",
        "        category_confidence = category_probs[category_pred_idx].item()\n",
        "        category_label = category_decoder[category_pred_idx]\n",
        "\n",
        "        ner_logits = outputs[\"ner_logits\"][0]\n",
        "        ner_probs = F.softmax(ner_logits, dim=-1)\n",
        "        ner_pred_idxs = torch.argmax(ner_probs, dim=-1).tolist()\n",
        "        ner_confidences = torch.max(ner_probs, dim=-1).values.tolist()\n",
        "        ner_labels = [ner_decoder[idx] for idx in ner_pred_idxs]\n",
        "\n",
        "        seq_len = inputs[\"gpt2_attention_mask\"][0].sum().item()\n",
        "        ner_labels = ner_labels[:seq_len]\n",
        "        ner_confidences = ner_confidences[:seq_len]\n",
        "        offset_mapping = offset_mapping[:seq_len]\n",
        "\n",
        "    # Detect entity spans\n",
        "    entities = []\n",
        "    current_entity = None\n",
        "    entity_start = None\n",
        "    entity_confidences = []\n",
        "\n",
        "    for i, (label, conf, (start, end)) in enumerate(zip(ner_labels, ner_confidences, offset_mapping)):\n",
        "        if label.startswith(\"B-\"):\n",
        "            if current_entity is not None:\n",
        "                entity_text = input_text[entity_start:start]\n",
        "                entities.append({\n",
        "                    \"entity\": entity_text.strip(),\n",
        "                    \"label\": current_entity,\n",
        "                    \"confidence\": sum(entity_confidences) / len(entity_confidences)\n",
        "                })\n",
        "            current_entity = label[2:]\n",
        "            entity_start = start\n",
        "            entity_confidences = [conf]\n",
        "\n",
        "        elif label.startswith(\"I-\") and current_entity == label[2:]:\n",
        "            entity_confidences.append(conf)\n",
        "\n",
        "        elif label == \"O\" and current_entity is not None:\n",
        "            entity_text = input_text[entity_start:start]\n",
        "            entities.append({\n",
        "                \"entity\": entity_text.strip(),\n",
        "                \"label\": current_entity,\n",
        "                \"confidence\": sum(entity_confidences) / len(entity_confidences)\n",
        "            })\n",
        "            current_entity = None\n",
        "            entity_confidences = []\n",
        "\n",
        "    if current_entity is not None:\n",
        "        entity_text = input_text[entity_start:offset_mapping[-1][1]]\n",
        "        entities.append({\n",
        "            \"entity\": entity_text.strip(),\n",
        "            \"label\": current_entity,\n",
        "            \"confidence\": sum(entity_confidences) / len(entity_confidences)\n",
        "        })\n",
        "\n",
        "    results = {\n",
        "        \"intent\": {\"label\": intent_label, \"confidence\": intent_confidence},\n",
        "        \"category\": {\"label\": category_label, \"confidence\": category_confidence},\n",
        "        \"ner\": entities\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "input_text = \"I want a refund amount of $2323 now\"\n",
        "results = run_inference(\n",
        "    model_path=\"MyDrive/thesis/hybrid/test_1/model/full_model.pt\",\n",
        "    gpt2_tokenizer_path=\"MyDrive/thesis/hybrid/test_1/gpt2_tokenizer\",\n",
        "    distilbert_tokenizer_path=\"MyDrive/thesis/hybrid/test_1/distilbert_tokenizer\",\n",
        "    label_encoders_path=\"MyDrive/thesis/hybrid/test_1/label_encoders.json\",\n",
        "    input_text=input_text\n",
        ")\n",
        "\n",
        "print(\"Inference Results:\")\n",
        "print(f\"Intent: {results['intent']['label']} (Confidence: {results['intent']['confidence']:.4f})\")\n",
        "print(f\"Category: {results['category']['label']} (Confidence: {results['category']['confidence']:.4f})\")\n",
        "print(\"NER:\")\n",
        "for entity in results['ner']:\n",
        "    print(f\"  Entity: {entity['entity']} | Label: {entity['label']} | Confidence: {entity['confidence']:.4f}\")"
      ],
      "metadata": {
        "id": "ic73a58d1WY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}