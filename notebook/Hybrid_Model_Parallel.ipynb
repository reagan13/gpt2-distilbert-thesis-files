{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "gbKval_1PJak"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reagan13/gpt2-distilbert-thesis-files/blob/main/notebook/Hybrid_Model_Parallel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multitask Learning with Hybrid (GPT2-Distilbert)"
      ],
      "metadata": {
        "id": "WU5-iqe8XY46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "uDdgWxvqUIgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports and Setup\n",
        "# (Add DistilBERT imports)\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from typing import List, Dict, Optional\n",
        "from collections import Counter, defaultdict\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    GPT2Model, GPT2Config, GPT2TokenizerFast,\n",
        "    DistilBertModel, DistilBertTokenizerFast,  # Added DistilBERT imports\n",
        "    AdamW, get_linear_schedule_with_warmup\n",
        ")\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from datetime import datetime\n",
        "\n",
        "# Device setup remains the same\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Selected device: {device}\")\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Initial GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    print(\"No GPU detected. Running on CPU.\")\n",
        "\n",
        "# check_device and setup_logging functions remain unchanged\n",
        "def check_device(item, name=\"Item\"):\n",
        "    if isinstance(item, torch.nn.Module):\n",
        "        param = next(item.parameters(), None)\n",
        "        if param is not None:\n",
        "            print(f\"{name} is on: {param.device}\")\n",
        "        else:\n",
        "            print(f\"{name} has no parameters to check\")\n",
        "    elif isinstance(item, torch.Tensor):\n",
        "        print(f\"{name} is on: {item.device}\")\n",
        "    else:\n",
        "        print(f\"{name} is not a tensor or model: {type(item)}\")\n",
        "\n",
        "def setup_logging(save_path: str, filename: str = \"training_log.txt\"):\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    log_path = os.path.join(save_path, filename)\n",
        "    class Logger:\n",
        "        def __init__(self, file_handle, original_stdout):\n",
        "            self.file = file_handle\n",
        "            self.stdout = original_stdout\n",
        "        def write(self, message):\n",
        "            self.file.write(message)\n",
        "            self.stdout.write(message)\n",
        "        def flush(self):\n",
        "            self.file.flush()\n",
        "            self.stdout.flush()\n",
        "    log_file = open(log_path, \"w\", encoding=\"utf-8\")\n",
        "    sys.stdout = Logger(log_file, sys.stdout)\n",
        "    print(f\"Logging started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"Log file: {log_path}\")\n",
        "\n",
        "print(f\"Current date: March 06, 2025\")\n"
      ],
      "metadata": {
        "id": "CKCve4yhUHS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Daset Loading Functions"
      ],
      "metadata": {
        "id": "G9xMYvhFUMeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_dataset(json_file: str) -> List[Dict]:\n",
        "    with open(json_file, 'r', encoding='utf-8') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def detect_labels(data: List[Dict]) -> Dict[str, Dict]:\n",
        "    start_time = time.time()\n",
        "    if not isinstance(data, list):\n",
        "        raise TypeError(\"Input 'data' must be a list of dictionaries\")\n",
        "    if not data:\n",
        "        return {\"category_encoder\": {}, \"intent_encoder\": {}, \"ner_label_encoder\": {\"O\": 0}}\n",
        "\n",
        "    unique_categories = set()\n",
        "    unique_intents = set()\n",
        "    unique_ner_labels = set([\"O\"])\n",
        "    missing_fields = defaultdict(int)\n",
        "    category_counts = Counter()\n",
        "    intent_counts = Counter()\n",
        "    ner_counts = Counter()\n",
        "\n",
        "    for i, sample in enumerate(data):\n",
        "        try:\n",
        "            category = sample[\"category\"]\n",
        "            intent = sample[\"intent\"]\n",
        "            unique_categories.add(category)\n",
        "            unique_intents.add(intent)\n",
        "            category_counts[category] += 1\n",
        "            intent_counts[intent] += 1\n",
        "            ner_labels = sample[\"ner_labels_only\"]\n",
        "            if not isinstance(ner_labels, list):\n",
        "                raise ValueError(f\"'ner_labels_only' must be a list at sample {i}\")\n",
        "            for label in ner_labels:\n",
        "                if not isinstance(label, dict) or \"label\" not in label or \"text\" not in label:\n",
        "                    raise ValueError(f\"NER label must have 'label' and 'text' fields at sample {i}\")\n",
        "                label_type = label[\"label\"]\n",
        "                unique_ner_labels.add(f\"B-{label_type}\")\n",
        "                unique_ner_labels.add(f\"I-{label_type}\")\n",
        "                ner_counts[f\"B-{label_type}\"] += 1\n",
        "                ner_counts[f\"I-{label_type}\"] += 1\n",
        "        except KeyError as e:\n",
        "            missing_fields[str(e).strip(\"'\")] += 1\n",
        "            continue\n",
        "\n",
        "    if missing_fields:\n",
        "        print(\"Warning: Missing fields detected:\")\n",
        "        for field, count in missing_fields.items():\n",
        "            print(f\"  - '{field}' missing in {count} samples\")\n",
        "\n",
        "    category_encoder = {cat: idx for idx, cat in enumerate(sorted(unique_categories))}\n",
        "    intent_encoder = {intent: idx for idx, intent in enumerate(sorted(unique_intents))}\n",
        "    ner_label_encoder = {ner: idx for idx, ner in enumerate(sorted(unique_ner_labels))}\n",
        "\n",
        "    print(f\"Dataset summary:\\n  - {len(data)} samples\\n  - {len(category_encoder)} categories\\n  - {len(intent_encoder)} intents\\n  - {len(ner_label_encoder)} NER tags\")\n",
        "    print(\"Category distribution:\", dict(category_counts))\n",
        "    print(\"Intent distribution:\", dict(intent_counts))\n",
        "    print(\"NER tag distribution (non-O):\", dict(ner_counts))\n",
        "    print(f\"Processing time: {time.time() - start_time:.3f} seconds\")\n",
        "\n",
        "    return {\"category_encoder\": category_encoder, \"intent_encoder\": intent_encoder, \"ner_label_encoder\": ner_label_encoder}\n"
      ],
      "metadata": {
        "id": "NQhYy09xUPAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization and NER Alignment"
      ],
      "metadata": {
        "id": "ZSJYDchMUT20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 3: Tokenization and NER Alignment (Updated for Dual Tokenizers)\n",
        "def tokenize_text_hybrid(text: str, gpt2_tokenizer, distilbert_tokenizer, max_length: int) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Tokenize text using both GPT-2 and DistilBERT tokenizers.\"\"\"\n",
        "    gpt2_inputs = gpt2_tokenizer(\n",
        "        text, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    distilbert_inputs = distilbert_tokenizer(\n",
        "        text, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    return {\n",
        "        \"gpt2_input_ids\": gpt2_inputs[\"input_ids\"].squeeze(0),\n",
        "        \"gpt2_attention_mask\": gpt2_inputs[\"attention_mask\"].squeeze(0),\n",
        "        \"distilbert_input_ids\": distilbert_inputs[\"input_ids\"].squeeze(0),\n",
        "        \"distilbert_attention_mask\": distilbert_inputs[\"attention_mask\"].squeeze(0)\n",
        "    }\n",
        "\n",
        "def align_ner_labels(text: str, ner_labels: List[Dict], tokenizer, ner_label_encoder: Dict, max_length: int) -> torch.Tensor:\n",
        "    \"\"\"Align NER labels with tokenized input (unchanged, using GPT-2 tokenizer for consistency).\"\"\"\n",
        "    sorted_labels = sorted(ner_labels, key=lambda x: len(x[\"text\"]), reverse=True) if ner_labels else []\n",
        "    encoding = tokenizer(\n",
        "        text, max_length=max_length, padding=\"max_length\", truncation=True, return_offsets_mapping=True, return_tensors=\"pt\"\n",
        "    )\n",
        "    token_to_char_map = encoding[\"offset_mapping\"][0].tolist()\n",
        "    ner_aligned = [ner_label_encoder[\"O\"]] * max_length\n",
        "\n",
        "    for label in sorted_labels:\n",
        "        if \"text\" not in label or \"label\" not in label:\n",
        "            print(f\"Warning: Skipping invalid NER entry {label} (missing 'text' or 'label')\")\n",
        "            continue\n",
        "        try:\n",
        "            label_text, label_type = label[\"text\"], label[\"label\"]\n",
        "            start_pos = 0\n",
        "            while True:\n",
        "                label_start = text.find(label_text, start_pos)\n",
        "                if label_start == -1:\n",
        "                    break\n",
        "                label_end = label_start + len(label_text)\n",
        "                start_pos = label_end\n",
        "                first_token = True\n",
        "                for i, (start, end) in enumerate(token_to_char_map):\n",
        "                    if start == 0 and end == 0:\n",
        "                        continue\n",
        "                    if max(start, label_start) < min(end, label_end):\n",
        "                        prefix = \"B-\" if first_token else \"I-\"\n",
        "                        first_token = False\n",
        "                        ner_aligned[i] = ner_label_encoder.get(f\"{prefix}{label_type}\", ner_label_encoder[\"O\"])\n",
        "        except KeyError as e:\n",
        "            print(f\"Warning: Label '{e}' not found in encoder. Skipping.\")\n",
        "\n",
        "    return torch.tensor(ner_aligned, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "9kMHmK7lUZUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and Dataloader"
      ],
      "metadata": {
        "id": "ee_1s8_LUb-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 4: Dataset and DataLoader (Updated)\n",
        "class HybridMultiTaskDataset(Dataset):\n",
        "    def __init__(self, data: List[Dict], gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length: int):\n",
        "        self.data = data\n",
        "        self.gpt2_tokenizer = gpt2_tokenizer\n",
        "        self.distilbert_tokenizer = distilbert_tokenizer\n",
        "        self.label_encoders = label_encoders\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        text = sample[\"instruction\"]\n",
        "        hybrid_inputs = tokenize_text_hybrid(text, self.gpt2_tokenizer, self.distilbert_tokenizer, self.max_length)\n",
        "        ner_labels = align_ner_labels(text, sample[\"ner_labels_only\"], self.gpt2_tokenizer, self.label_encoders[\"ner_label_encoder\"], self.max_length)\n",
        "\n",
        "        return {\n",
        "            \"gpt2_input_ids\": hybrid_inputs[\"gpt2_input_ids\"],\n",
        "            \"gpt2_attention_mask\": hybrid_inputs[\"gpt2_attention_mask\"],\n",
        "            \"distilbert_input_ids\": hybrid_inputs[\"distilbert_input_ids\"],\n",
        "            \"distilbert_attention_mask\": hybrid_inputs[\"distilbert_attention_mask\"],\n",
        "            \"category_labels\": torch.tensor(self.label_encoders[\"category_encoder\"][sample[\"category\"]], dtype=torch.long),\n",
        "            \"intent_labels\": torch.tensor(self.label_encoders[\"intent_encoder\"][sample[\"intent\"]], dtype=torch.long),\n",
        "            \"ner_labels\": ner_labels\n",
        "        }\n",
        "\n",
        "def get_dataloaders(train_data, val_data, test_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, batch_size, num_workers, max_length):\n",
        "    pin_memory = device.type == \"cuda\"\n",
        "    train_dataset = HybridMultiTaskDataset(train_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length)\n",
        "    val_dataset = HybridMultiTaskDataset(val_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length)\n",
        "    test_dataset = HybridMultiTaskDataset(test_data, gpt2_tokenizer, distilbert_tokenizer, label_encoders, max_length)\n",
        "\n",
        "    return (\n",
        "        DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory),\n",
        "        DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "    )"
      ],
      "metadata": {
        "id": "wYt1cv-1UePb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture"
      ],
      "metadata": {
        "id": "8_kvjRnHUfo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 5: Model Definition (Hybrid Model)\n",
        "class FusionLayer(nn.Module):\n",
        "    def __init__(self, gpt2_dim: int, bert_dim: int, output_dim: int, dropout_rate: float = 0.4):\n",
        "        super().__init__()\n",
        "        self.gpt2_proj = nn.Linear(gpt2_dim, output_dim)\n",
        "        self.bert_proj = nn.Linear(bert_dim, output_dim)\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(output_dim * 2, output_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(output_dim)\n",
        "\n",
        "    def forward(self, gpt2_features: torch.Tensor, bert_features: torch.Tensor) -> torch.Tensor:\n",
        "        gpt2_proj = self.gpt2_proj(gpt2_features)\n",
        "        bert_proj = self.bert_proj(bert_features)\n",
        "        concat_features = torch.cat([gpt2_proj, bert_proj], dim=-1)\n",
        "        fused = self.fusion(concat_features)\n",
        "        return self.layer_norm(fused)\n",
        "\n",
        "class HybridGPT2DistilBERTMultiTask(nn.Module):\n",
        "    def __init__(self, num_intents: int, num_categories: int, num_ner_labels: int, dropout_rate: float = 0.4):\n",
        "        super().__init__()\n",
        "        self.gpt2_config = GPT2Config.from_pretrained('gpt2')\n",
        "        self.gpt2 = GPT2Model.from_pretrained('gpt2')\n",
        "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "        for param in self.gpt2.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.distilbert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        gpt2_dim = self.gpt2_config.n_embd\n",
        "        bert_dim = self.distilbert.config.hidden_size\n",
        "        hidden_size = gpt2_dim\n",
        "\n",
        "        self.fusion_layer = FusionLayer(gpt2_dim, bert_dim, hidden_size, dropout_rate)\n",
        "\n",
        "        self.intent_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, num_intents)\n",
        "        )\n",
        "        self.category_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, num_categories)\n",
        "        )\n",
        "        self.ner_head = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, num_ner_labels)\n",
        "        )\n",
        "\n",
        "        self.intent_loss_fn = nn.CrossEntropyLoss()\n",
        "        self.category_loss_fn = nn.CrossEntropyLoss()\n",
        "        self.ner_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, gpt2_input_ids: torch.Tensor, gpt2_attention_mask: torch.Tensor,\n",
        "                distilbert_input_ids: torch.Tensor, distilbert_attention_mask: torch.Tensor,\n",
        "                intent_labels: Optional[torch.Tensor] = None,\n",
        "                category_labels: Optional[torch.Tensor] = None,\n",
        "                ner_labels: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        gpt2_outputs = self.gpt2(input_ids=gpt2_input_ids, attention_mask=gpt2_attention_mask)\n",
        "        distilbert_outputs = self.distilbert(input_ids=distilbert_input_ids, attention_mask=distilbert_attention_mask)\n",
        "\n",
        "        gpt2_features = gpt2_outputs.last_hidden_state\n",
        "        bert_features = distilbert_outputs.last_hidden_state\n",
        "\n",
        "        fused_features = self.fusion_layer(gpt2_features, bert_features)\n",
        "\n",
        "        batch_size = fused_features.shape[0]\n",
        "        sequence_lengths = gpt2_attention_mask.sum(dim=1) - 1\n",
        "        last_token_indexes = sequence_lengths.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, fused_features.shape[-1])\n",
        "        sequence_repr = torch.gather(fused_features, 1, last_token_indexes).squeeze(1)\n",
        "\n",
        "        intent_logits = self.intent_head(sequence_repr)\n",
        "        category_logits = self.category_head(sequence_repr)\n",
        "        ner_logits = self.ner_head(fused_features)\n",
        "\n",
        "        output_dict = {\n",
        "            'intent_logits': intent_logits,\n",
        "            'category_logits': category_logits,\n",
        "            'ner_logits': ner_logits\n",
        "        }\n",
        "\n",
        "        if all(label is not None for label in [intent_labels, category_labels, ner_labels]):\n",
        "            intent_loss = self.intent_loss_fn(intent_logits, intent_labels)\n",
        "            category_loss = self.category_loss_fn(category_logits, category_labels)\n",
        "            active_loss = gpt2_attention_mask.view(-1) == 1\n",
        "            active_logits = ner_logits.view(-1, ner_logits.size(-1))[active_loss]\n",
        "            active_labels = ner_labels.view(-1)[active_loss]\n",
        "            ner_loss = self.ner_loss_fn(active_logits, active_labels)\n",
        "\n",
        "            output_dict.update({\n",
        "                'loss': intent_loss + category_loss + ner_loss,\n",
        "                'intent_loss': intent_loss,\n",
        "                'category_loss': category_loss,\n",
        "                'ner_loss': ner_loss\n",
        "            })\n",
        "\n",
        "        return output_dict"
      ],
      "metadata": {
        "id": "SQeWYh9uUg7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "id": "DEhnmgZNUkU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 6: Training Function (Updated)\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs, learning_rate):\n",
        "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
        "    history = {\n",
        "        \"train_loss\": [], \"val_loss\": [],\n",
        "        \"train_intent_acc\": [], \"val_intent_acc\": [],\n",
        "        \"train_category_f1\": [], \"val_category_f1\": [],\n",
        "        \"train_ner_f1\": [], \"val_ner_f1\": []\n",
        "    }\n",
        "\n",
        "    model.to(device)\n",
        "    check_device(model, \"Model\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        all_train_intent_preds, all_train_intent_labels = [], []\n",
        "        all_train_category_preds, all_train_category_labels = [], []\n",
        "        all_train_ner_preds, all_train_ner_labels = [], []\n",
        "\n",
        "        with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False) as train_loop:\n",
        "            for i, batch in enumerate(train_loop):\n",
        "                optimizer.zero_grad()\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "                if i == 0 and epoch == 0:\n",
        "                    check_device(inputs[\"gpt2_input_ids\"], \"GPT2 Input IDs\")\n",
        "                    check_device(inputs[\"distilbert_input_ids\"], \"DistilBERT Input IDs\")\n",
        "                    print(f\"GPU Memory Allocated After Data Load: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
        "\n",
        "                outputs = model(**inputs)\n",
        "                loss = outputs[\"loss\"]\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "                intent_preds = torch.argmax(outputs[\"intent_logits\"], dim=-1).cpu().numpy()\n",
        "                category_preds = torch.argmax(outputs[\"category_logits\"], dim=-1).cpu().numpy()\n",
        "                ner_preds = torch.argmax(outputs[\"ner_logits\"], dim=-1).cpu().numpy()\n",
        "\n",
        "                all_train_intent_preds.extend(intent_preds)\n",
        "                all_train_intent_labels.extend(batch[\"intent_labels\"].cpu().numpy())\n",
        "                all_train_category_preds.extend(category_preds)\n",
        "                all_train_category_labels.extend(batch[\"category_labels\"].cpu().numpy())\n",
        "                all_train_ner_preds.extend(ner_preds.flatten())\n",
        "                all_train_ner_labels.extend(batch[\"ner_labels\"].cpu().numpy().flatten())\n",
        "\n",
        "        train_intent_acc = accuracy_score(all_train_intent_labels, all_train_intent_preds)\n",
        "        train_category_f1 = precision_recall_fscore_support(all_train_category_labels, all_train_category_preds, average=\"macro\", zero_division=0)[2]\n",
        "        train_ner_f1 = precision_recall_fscore_support(all_train_ner_labels, all_train_ner_preds, average=\"macro\", zero_division=0)[2]\n",
        "\n",
        "        history[\"train_loss\"].append(total_loss / len(train_loader))\n",
        "        history[\"train_intent_acc\"].append(train_intent_acc)\n",
        "        history[\"train_category_f1\"].append(train_category_f1)\n",
        "        history[\"train_ner_f1\"].append(train_ner_f1)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_val_intent_preds, all_val_intent_labels = [], []\n",
        "        all_val_category_preds, all_val_category_labels = [], []\n",
        "        all_val_ner_preds, all_val_ner_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False):\n",
        "                inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "                outputs = model(**inputs)\n",
        "                val_loss += outputs[\"loss\"].item()\n",
        "\n",
        "                intent_preds = torch.argmax(outputs[\"intent_logits\"], dim=-1).cpu().numpy()\n",
        "                category_preds = torch.argmax(outputs[\"category_logits\"], dim=-1).cpu().numpy()\n",
        "                ner_preds = torch.argmax(outputs[\"ner_logits\"], dim=-1).cpu().numpy()\n",
        "\n",
        "                all_val_intent_preds.extend(intent_preds)\n",
        "                all_val_intent_labels.extend(batch[\"intent_labels\"].cpu().numpy())\n",
        "                all_val_category_preds.extend(category_preds)\n",
        "                all_val_category_labels.extend(batch[\"category_labels\"].cpu().numpy())\n",
        "                all_val_ner_preds.extend(ner_preds.flatten())\n",
        "                all_val_ner_labels.extend(batch[\"ner_labels\"].cpu().numpy().flatten())\n",
        "\n",
        "        val_intent_acc = accuracy_score(all_val_intent_labels, all_val_intent_preds)\n",
        "        val_category_f1 = precision_recall_fscore_support(all_val_category_labels, all_val_category_preds, average=\"macro\", zero_division=0)[2]\n",
        "        val_ner_f1 = precision_recall_fscore_support(all_val_ner_labels, all_val_ner_preds, average=\"macro\", zero_division=0)[2]\n",
        "\n",
        "        history[\"val_loss\"].append(val_loss / len(val_loader))\n",
        "        history[\"val_intent_acc\"].append(val_intent_acc)\n",
        "        history[\"val_category_f1\"].append(val_category_f1)\n",
        "        history[\"val_ner_f1\"].append(val_ner_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
        "        print(f\"  Train Loss:      {history['train_loss'][-1]:.4f}\")\n",
        "        print(f\"  Val Loss:       {history['val_loss'][-1]:.4f}\\n\")\n",
        "        print(f\"  Train Intent Acc: {train_intent_acc:.4f}\")\n",
        "        print(f\"  Val Intent Acc:  {val_intent_acc:.4f}\\n\")\n",
        "        print(f\"  Train Category F1:{train_category_f1:.4f}\")\n",
        "        print(f\"  Val Category F1: {val_category_f1:.4f}\\n\")\n",
        "        print(f\"  Train NER F1:     {train_ner_f1:.4f}\")\n",
        "        print(f\"  Val NER F1:      {val_ner_f1:.4f}\\n\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "rN3W8kTDUlTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "r_W1hO4EUmly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 7: Evaluation Function (Updated)\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_intent_preds, all_intent_labels = [], []\n",
        "    all_category_preds, all_category_labels = [], []\n",
        "    all_ner_preds, all_ner_labels = [], []\n",
        "    total_loss = 0\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    test_loop = tqdm(test_loader, desc=\"Evaluation\", leave=True)\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loop:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**inputs)\n",
        "            batch_loss = outputs[\"loss\"].item()\n",
        "            total_loss += batch_loss\n",
        "            test_loop.set_postfix(loss=batch_loss)\n",
        "\n",
        "            intent_preds = torch.argmax(outputs[\"intent_logits\"], dim=-1).cpu().numpy()\n",
        "            category_preds = torch.argmax(outputs[\"category_logits\"], dim=-1).cpu().numpy()\n",
        "            ner_preds = torch.argmax(outputs[\"ner_logits\"], dim=-1).cpu().numpy()\n",
        "\n",
        "            all_intent_preds.extend(intent_preds)\n",
        "            all_intent_labels.extend(batch[\"intent_labels\"].cpu().numpy())\n",
        "            all_category_preds.extend(category_preds)\n",
        "            all_category_labels.extend(batch[\"category_labels\"].cpu().numpy())\n",
        "            all_ner_preds.extend(ner_preds.flatten())\n",
        "            all_ner_labels.extend(batch[\"ner_labels\"].cpu().numpy().flatten())\n",
        "\n",
        "    intent_acc = accuracy_score(all_intent_labels, all_intent_preds)\n",
        "    category_f1 = precision_recall_fscore_support(all_category_labels, all_category_preds, average=\"macro\", zero_division=0)[2]\n",
        "    ner_f1 = precision_recall_fscore_support(all_ner_labels, all_ner_preds, average=\"macro\", zero_division=0)[2]\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "    print(f\"Test Results:\")\n",
        "    print(f\"  Loss:            {avg_loss:.4f}\")\n",
        "    print(f\"  Intent Acc:      {intent_acc:.4f}\")\n",
        "    print(f\"  Category F1:     {category_f1:.4f}\")\n",
        "    print(f\"  NER F1:          {ner_f1:.4f}\")\n",
        "\n",
        "    return {\"loss\": avg_loss, \"intent_accuracy\": intent_acc, \"category_f1\": category_f1, \"ner_f1\": ner_f1}\n"
      ],
      "metadata": {
        "id": "GvXcNp4vUoWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Artifacts"
      ],
      "metadata": {
        "id": "3TL8MuAeUrFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 8: Save Functions (Unchanged)\n",
        "def save_training_artifacts(model, gpt2_tokenizer, label_encoders, metrics, test_results, save_path):\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, \"model.pth\"))\n",
        "    gpt2_tokenizer.save_pretrained(os.path.join(save_path, \"gpt2_tokenizer\"))\n",
        "    with open(os.path.join(save_path, \"label_encoders.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(label_encoders, f, ensure_ascii=False, indent=4)\n",
        "    with open(os.path.join(save_path, \"training_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=4)\n",
        "    with open(os.path.join(save_path, \"test_results.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(test_results, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Artifacts saved to {save_path}\")"
      ],
      "metadata": {
        "id": "NTNnt-hVUsle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving training config"
      ],
      "metadata": {
        "id": "0kp5itQ3UvXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def save_training_config(config: dict, save_path: str, filename: str = \"training_config.json\"):\n",
        "    \"\"\"\n",
        "    Save the training configuration to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        config (dict): Dictionary containing training hyperparameters.\n",
        "        save_path (str): Directory where the config file will be saved.\n",
        "        filename (str): Name of the config file (default: \"training_config.json\").\n",
        "    \"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    config_path = os.path.join(save_path, filename)\n",
        "\n",
        "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Training configuration saved to {config_path}\")"
      ],
      "metadata": {
        "id": "FF-dJPm_Uu-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "h4bzEoBpUzZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Save Model Functions\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "\n",
        "def save_full_model(model, gpt2_tokenizer, label_encoders, metrics, test_results, save_path):\n",
        "    \"\"\"Save the entire model directly, tokenizer, label encoders, and results.\"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Save the full model (architecture + weights)\n",
        "    torch.save(model, os.path.join(save_path, \"full_model.pt\"))\n",
        "\n",
        "    # Save tokenizer\n",
        "    gpt2_tokenizer.save_pretrained(os.path.join(save_path, \"tokenizer\"))\n",
        "\n",
        "    # Save label encoders\n",
        "    with open(os.path.join(save_path, \"label_encoders.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(label_encoders, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    # Save training metrics\n",
        "    with open(os.path.join(save_path, \"training_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metrics, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    # Save test results\n",
        "    with open(os.path.join(save_path, \"test_results.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(test_results, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"Full model and artifacts saved to {save_path}\")\n"
      ],
      "metadata": {
        "id": "BDevalI0U0p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Execution"
      ],
      "metadata": {
        "id": "D_mQwQdBU4QS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paths and Hyperparameters"
      ],
      "metadata": {
        "id": "7v48SU_2U6DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Main Execution\n",
        "# Data paths and hyperparameters\n",
        "train_file = \"train.json\"\n",
        "val_file = \"val.json\"\n",
        "test_file = \"test.json\"\n",
        "batch_size = 16\n",
        "num_epochs = 1\n",
        "learning_rate = 2e-5\n",
        "max_length = 128\n",
        "num_workers = 2\n",
        "save_path = \"saved_models\"\n",
        "\n",
        "\n",
        "# Define training configuration\n",
        "training_config = {\n",
        "    \"train_file\": train_file,\n",
        "    \"val_file\": val_file,\n",
        "    \"test_file\": test_file,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"num_epochs\": num_epochs,\n",
        "    \"learning_rate\": learning_rate,\n",
        "    \"max_length\": max_length,\n",
        "    \"num_workers\": num_workers,\n",
        "    \"model_name\": \"BaselineGPT2MultiTask\",\n",
        "    \"gpt2_base\": \"gpt2\",\n",
        "    \"dropout_rate\": 0.4,\n",
        "    \"device\": str(device),\n",
        "    \"date\": \"March 06, 2025\"\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "CiubTK2NU5h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "-pIstRkZU-Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load datasets\n",
        "print(\"Loading datasets...\\n\")\n",
        "train_data = load_dataset(train_file)[:100]  # Limited for demo\n",
        "val_data = load_dataset(val_file)[:20]\n",
        "test_data = load_dataset(test_file)[:20]\n",
        "\n",
        "print(\"*\" * 30)\n",
        "print(f\"\"\"Dataset Summary:\n",
        "Training samples: {len(train_data)}\n",
        "Validation samples: {len(val_data)}\n",
        "Test samples: {len(test_data)}\"\"\")\n",
        "\n",
        "# Detect labels\n",
        "label_encoders = detect_labels(train_data)\n",
        "\n",
        "\n",
        "# Initialize tokenizer\n",
        "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained('gpt2')\n",
        "if gpt2_tokenizer.pad_token is None:\n",
        "    gpt2_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# Create data loaders\n",
        "train_loader, val_loader, test_loader = get_dataloaders(\n",
        "    train_data, val_data, test_data, gpt2_tokenizer, label_encoders, batch_size, num_workers, max_length\n",
        ")\n",
        "\n",
        "# Initialize model\n",
        "model = BaselineGPT2MultiTask(\n",
        "    num_intents=len(label_encoders[\"intent_encoder\"]),\n",
        "    num_categories=len(label_encoders[\"category_encoder\"]),\n",
        "    num_ner_labels=len(label_encoders[\"ner_label_encoder\"])\n",
        ")\n",
        "if gpt2_tokenizer.pad_token_id is not None:\n",
        "    model.gpt2.resize_token_embeddings(len(gpt2_tokenizer))\n",
        "\n",
        "# Setup logging to save print statements\n",
        "setup_logging(save_path)\n",
        "\n",
        "model.to(device)  # Ensure model is moved to GPU\n",
        "check_device(model, \"Model before training\")  # Verify\n",
        "\n",
        "# Save training config before training\n",
        "save_training_config(training_config, save_path)\n",
        "\n",
        "# Train model\n",
        "print(\"*\" * 30)\n",
        "print(\"Starting training...\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "metrics = train_model(model, train_loader, val_loader, num_epochs, learning_rate)\n",
        "print(f\"Training completed in {(time.time() - start_time) / 60:.2f} minutes\")\n",
        "\n",
        "print(\"*\" * 30)\n",
        "\n",
        "# Evaluate model\n",
        "print(\"Evaluating on test set...\")\n",
        "test_results = evaluate_model(model, test_loader)\n",
        "\n",
        "# Save artifacts\n",
        "save_training_artifacts(model, gpt2_tokenizer, label_encoders, metrics, test_results, save_path)\n",
        "\n",
        "# Save Full model\n",
        "save_full_model(model, gpt2_tokenizer, label_encoders, metrics, test_results, save_path)\n"
      ],
      "metadata": {
        "id": "gt_Gsk_LVAZI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}