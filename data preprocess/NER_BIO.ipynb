{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Import\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Load Data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {},
			"outputs": [],
			"source": [
				"\n",
				"df = pd.read_csv('../dataset/dataset.csv')\n",
				"\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Small Datapreprocess\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Before removing nulls:\n",
						"object\n",
						"0\n",
						"\n",
						"After removing nulls:\n",
						"object\n",
						"0\n",
						"   flags                                        instruction category  \\\n",
						"0      B   question about cancelling order {{Order Number}}    ORDER   \n",
						"1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
						"2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
						"3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
						"4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
						"\n",
						"         intent                                           response  \n",
						"0  cancel_order  I've understood you have a question regarding ...  \n",
						"1  cancel_order  I've been informed that you have a question ab...  \n",
						"2  cancel_order  I can sense that you're seeking assistance wit...  \n",
						"3  cancel_order  I understood that you need assistance with can...  \n",
						"4  cancel_order  I'm sensitive to the fact that you're facing f...  \n"
					]
				}
			],
			"source": [
				"# Check data types and missing values before removal\n",
				"print(\"Before removing nulls:\")\n",
				"print(df['instruction'].dtype)\n",
				"print(df['instruction'].isnull().sum())\n",
				"\n",
				"# Remove rows with null values in 'instruction_augmented' column\n",
				"df = df.dropna(subset=['instruction'])\n",
				"\n",
				"# Check data types and missing values after removal\n",
				"print(\"\\nAfter removing nulls:\")\n",
				"print(df['instruction'].dtype)\n",
				"print(df['instruction'].isnull().sum())\n",
				"\n",
				"\n",
				"# Now you can work with the 'data' DataFrame\n",
				"print(df.head())\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Identify Placeholder\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"for augmented dataset\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"import pandas as pd\n",
				"import re\n",
				"from collections import Counter\n",
				"\n",
				"# Detect rows with placeholders\n",
				"df['has_placeholder'] = df['instruction_augmented'].str.contains(r'\\{\\{.*?\\}\\}')\n",
				"\n",
				"# Count rows with placeholders\n",
				"rows_with_placeholders = df['has_placeholder'].sum()\n",
				"\n",
				"# Extract placeholders function\n",
				"def extract_placeholders(text):\n",
				"    return re.findall(r'\\{\\{(.*?)\\}\\}', text)\n",
				"\n",
				"# Apply function and get all placeholders\n",
				"placeholders = df[df['has_placeholder']]['instruction_augmented'].apply(extract_placeholders).explode()\n",
				"\n",
				"# Count occurrences of each placeholder\n",
				"placeholder_counts = Counter(placeholders)\n",
				"\n",
				"# Convert to DataFrame (including frequency count)\n",
				"placeholder_df = pd.DataFrame(placeholder_counts.items(), columns=['placeholder', 'frequency'])\n",
				"\n",
				"# Sort by frequency in descending order\n",
				"placeholder_df = placeholder_df.sort_values(by='frequency', ascending=False)\n",
				"\n",
				"# Display results\n",
				"print(f\"Rows with placeholders: {rows_with_placeholders}\")\n",
				"print(f\"Total unique placeholders: {len(placeholder_df)}\\n\")\n",
				"\n",
				"print(\"Distribution of Placeholders (Frequency Count):\")\n",
				"print(placeholder_df)\n",
				"\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"for old dataset\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"instruction only\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Rows with placeholders: 6670\n",
						"Total unique placeholders: 9\n",
						"\n",
						"Distribution of Placeholders (Frequency Count):\n",
						"        placeholder  frequency\n",
						"0      Order Number       2907\n",
						"3      Account Type       1011\n",
						"2       Person Name        887\n",
						"4  Account Category        822\n",
						"8     Refund Amount        624\n",
						"7   Currency Symbol        372\n",
						"5     Delivery City        234\n",
						"6  Delivery Country        177\n",
						"1    Invoice Number          8\n",
						"Placeholders saved to 'unique_placeholders.txt'.\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"import re\n",
				"from collections import Counter\n",
				"\n",
				"# Detect rows with placeholders in 'instruction'\n",
				"df['has_placeholder'] = df['instruction'].str.contains(r'\\{\\{.*?\\}\\}', na=False)\n",
				"\n",
				"# Count rows with placeholders\n",
				"rows_with_placeholders = df['has_placeholder'].sum()\n",
				"\n",
				"# Function to extract placeholders from a given text\n",
				"def extract_placeholders(text):\n",
				"    return re.findall(r'\\{\\{(.*?)\\}\\}', str(text))\n",
				"\n",
				"# Apply function to 'instruction' column to get all placeholders\n",
				"placeholders_instruction = df[df['instruction'].str.contains(r'\\{\\{.*?\\}\\}', na=False)]['instruction'].apply(extract_placeholders).explode()\n",
				"\n",
				"# Count occurrences of each placeholder\n",
				"placeholder_counts = Counter(placeholders_instruction)\n",
				"\n",
				"# Convert to DataFrame (including frequency count)\n",
				"placeholder_df = pd.DataFrame(placeholder_counts.items(), columns=['placeholder', 'frequency'])\n",
				"\n",
				"# Sort by frequency in descending order\n",
				"placeholder_df = placeholder_df.sort_values(by='frequency', ascending=False)\n",
				"\n",
				"# Display results\n",
				"print(f\"Rows with placeholders: {rows_with_placeholders}\")\n",
				"print(f\"Total unique placeholders: {len(placeholder_df)}\\n\")\n",
				"print(\"Distribution of Placeholders (Frequency Count):\")\n",
				"print(placeholder_df)\n",
				"\n",
				"# Optionally, save only the list of unique placeholders (without frequencies)\n",
				"unique_placeholders = placeholder_df['placeholder'].tolist()\n",
				"with open('unique_placeholders.txt', 'w') as f:\n",
				"    f.write(\"Unique Placeholders:\\n\")\n",
				"    for placeholder in unique_placeholders:\n",
				"        f.write(f\"{placeholder}\\n\")\n",
				"\n",
				"print(\"Placeholders saved to 'unique_placeholders.txt'.\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"both instruction or response\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Rows with placeholders: 13041\n",
						"Total unique placeholders: 391\n",
						"\n",
						"Distribution of Placeholders (Frequency Count):\n",
						"                           placeholder  frequency\n",
						"0                         Order Number       8029\n",
						"3                         Account Type       5440\n",
						"4                     Account Category       3900\n",
						"10            Online Order Interaction       2699\n",
						"12       Customer Support Phone Number       2635\n",
						"..                                 ...        ...\n",
						"230                    Forgot PIN code          1\n",
						"231             Password Recovery Page          1\n",
						"80   Customer Service Toll-Free Number          1\n",
						"78                Social Media Handles          1\n",
						"262                 Account Management          1\n",
						"\n",
						"[391 rows x 2 columns]\n",
						"Placeholders saved to 'placeholders_with_frequencies.txt' and 'unique_placeholders.txt'.\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"import re\n",
				"from collections import Counter\n",
				"\n",
				"# Detect rows with placeholders in either 'instruction' or 'response'\n",
				"df['has_placeholder'] = (\n",
				"    df['instruction'].str.contains(r'\\{\\{.*?\\}\\}', na=False) | \n",
				"    df['response'].str.contains(r'\\{\\{.*?\\}\\}', na=False)\n",
				")\n",
				"\n",
				"# Count rows with placeholders\n",
				"rows_with_placeholders = df['has_placeholder'].sum()\n",
				"\n",
				"# Function to extract placeholders from a given text\n",
				"def extract_placeholders(text):\n",
				"    return re.findall(r'\\{\\{(.*?)\\}\\}', str(text))\n",
				"\n",
				"# Apply function to both 'instruction' and 'response' columns to get all placeholders\n",
				"placeholders_instruction = df[df['instruction'].str.contains(r'\\{\\{.*?\\}\\}', na=False)]['instruction'].apply(extract_placeholders).explode()\n",
				"placeholders_response = df[df['response'].str.contains(r'\\{\\{.*?\\}\\}', na=False)]['response'].apply(extract_placeholders).explode()\n",
				"\n",
				"# Concatenate placeholders from both columns\n",
				"placeholders = pd.concat([placeholders_instruction, placeholders_response])\n",
				"\n",
				"# Count occurrences of each placeholder\n",
				"placeholder_counts = Counter(placeholders)\n",
				"\n",
				"# Convert to DataFrame (including frequency count)\n",
				"placeholder_df = pd.DataFrame(placeholder_counts.items(), columns=['placeholder', 'frequency'])\n",
				"\n",
				"# Sort by frequency in descending order\n",
				"placeholder_df = placeholder_df.sort_values(by='frequency', ascending=False)\n",
				"\n",
				"# Display results\n",
				"print(f\"Rows with placeholders: {rows_with_placeholders}\")\n",
				"print(f\"Total unique placeholders: {len(placeholder_df)}\\n\")\n",
				"print(\"Distribution of Placeholders (Frequency Count):\")\n",
				"print(placeholder_df)\n",
				"\n",
				"# Optionally, save only the list of unique placeholders (without frequencies)\n",
				"unique_placeholders = placeholder_df['placeholder'].tolist()\n",
				"with open('unique_placeholders.txt', 'w') as f:\n",
				"    f.write(\"Unique Placeholders:\\n\")\n",
				"    for placeholder in unique_placeholders:\n",
				"        f.write(f\"{placeholder}\\n\")\n",
				"\n",
				"print(\"Placeholders saved to 'placeholders_with_frequencies.txt' and 'unique_placeholders.txt'.\")\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Generate Fake Data For Placeholder and Saved Data\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"   flags                                        instruction category  \\\n",
						"0      B        question about cancelling order ORD-5090958    ORDER   \n",
						"1    BQZ  i have a question about cancelling oorder ORD-...    ORDER   \n",
						"2   BLQZ         i need help cancelling puchase ORD-5914872    ORDER   \n",
						"3     BL              I need to cancel purchase ORD-3943164    ORDER   \n",
						"4  BCELN  I cannot afford this order, cancel purchase OR...    ORDER   \n",
						"\n",
						"         intent                                           response  \\\n",
						"0  cancel_order  I've understood you have a question regarding ...   \n",
						"1  cancel_order  I've been informed that you have a question ab...   \n",
						"2  cancel_order  I can sense that you're seeking assistance wit...   \n",
						"3  cancel_order  I understood that you need assistance with can...   \n",
						"4  cancel_order  I'm sensitive to the fact that you're facing f...   \n",
						"\n",
						"   has_placeholder                                    ner_labels_only  \n",
						"0             True  [{'text': 'ORD-5090958', 'label': 'order_numbe...  \n",
						"1             True  [{'text': 'ORD-8553488', 'label': 'order_numbe...  \n",
						"2             True  [{'text': 'ORD-5914872', 'label': 'order_numbe...  \n",
						"3             True  [{'text': 'ORD-3943164', 'label': 'order_numbe...  \n",
						"4             True  [{'text': 'ORD-8798992', 'label': 'order_numbe...  \n"
					]
				}
			],
			"source": [
				"\n",
				"import re\n",
				"import pandas as pd\n",
				"from faker import Faker\n",
				"\n",
				"# Initialize Faker\n",
				"fake = Faker()\n",
				"\n",
				"# Define synthetic data generators\n",
				"data_generators = {\n",
				"    'order number': lambda: fake.unique.bothify(text='ORD-#######'),\n",
				"    'invoice number': lambda: fake.unique.bothify(text='INV#####'),\n",
				"    'person name': lambda: fake.name(),\n",
				"    'account type': lambda: fake.random_element(elements=(\n",
				"        'Personal', 'Business', 'Corporate', 'Enterprise', 'VIP',\n",
				"        'Premium', 'Standard', 'Basic', 'Student', 'Non-Profit', 'Government'\n",
				"    )),\n",
				"    'account category': lambda: fake.random_element(elements=(\n",
				"        'Retail', 'E-commerce', 'Technology', 'Finance', 'Healthcare',\n",
				"        'Education', 'Real Estate', 'Hospitality', 'Manufacturing',\n",
				"        'Legal', 'Entertainment', 'Consulting', 'Logistics'\n",
				"    )),\n",
				"    'refund amount': lambda: f\"${fake.random_number(digits=3)}.00\",\n",
				"    'currency symbol': lambda: fake.currency_symbol(),\n",
				"    'delivery city': lambda: fake.city(),\n",
				"    'delivery country': lambda: fake.country()\n",
				"}\n",
				"\n",
				"# Function to replace placeholders and track NER labels\n",
				"def replace_placeholders(text, data_generators):\n",
				"    if pd.isnull(text):\n",
				"        return text, []  # Return empty list for NER labels\n",
				"\n",
				"    placeholder_pattern = re.compile(r'\\{\\{(.*?)\\}\\}')  # Match placeholders {{...}}\n",
				"    placeholders = placeholder_pattern.findall(text)\n",
				"    ner_labels = []  # Store entity labels\n",
				"\n",
				"    for placeholder in placeholders:\n",
				"        placeholder_cleaned = placeholder.strip().lower()  # Normalize case\n",
				"        if placeholder_cleaned in data_generators:\n",
				"            replacement_value = data_generators[placeholder_cleaned]()  # Generate synthetic data\n",
				"            text = text.replace(f'{{{{{placeholder}}}}}', replacement_value, 1)  # Replace placeholder\n",
				"\n",
				"            # Append entity info in required format\n",
				"            ner_labels.append({'text': replacement_value, 'label': placeholder_cleaned.replace(\" \", \"_\")})\n",
				"\n",
				"    return text, ner_labels\n",
				"\n",
				"# Apply the placeholder replacement function\n",
				"df[['instruction', 'ner_labels_only']] = df['instruction'].apply(\n",
				"    lambda x: pd.Series(replace_placeholders(x, data_generators))\n",
				")\n",
				"\n",
				"# Ensure all rows are retained, even if ner_labels is empty\n",
				"df['ner_labels_only'] = df.apply(lambda row: row['ner_labels_only'] if row['has_placeholder'] else [], axis=1)\n",
				"\n",
				"print(df.head())\n",
				"\n",
				"df.to_csv(\"generated_fake_data.csv\", index=False)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# Convert CSV TO JSON AND save FINAL DATA FOR TRAINING\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"CSV successfully converted to valid JSON format.\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"import json\n",
				"\n",
				"# Load the CSV file\n",
				"df = pd.read_csv(\"generated_fake_data.csv\")\n",
				"\n",
				"# Ensure the `ner_labels_only` column is properly formatted as JSON\n",
				"def fix_json_format(value):\n",
				"    \"\"\"\n",
				"    Fix JSON formatting issues in the 'ner_labels_only' column.\n",
				"    Ensures it is a valid JSON string.\n",
				"    \"\"\"\n",
				"    try:\n",
				"        # If already valid JSON, return as is\n",
				"        if isinstance(value, str):\n",
				"            return json.loads(value.replace(\"'\", \"\\\"\"))  # Replace single quotes with double quotes\n",
				"    except json.JSONDecodeError:\n",
				"        pass  # If there's an error, leave it as is (optional: log the error)\n",
				"    return []  # Default to empty list if there's an issue\n",
				"\n",
				"# Apply formatting fix\n",
				"df[\"ner_labels_only\"] = df[\"ner_labels_only\"].apply(fix_json_format)\n",
				"\n",
				"# Save as JSON file\n",
				"df.to_json(\"generated_fake_data.json\", orient=\"records\", indent=4)\n",
				"\n",
				"print(\"CSV successfully converted to valid JSON format.\")\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.11.9"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
