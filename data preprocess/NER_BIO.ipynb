{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('data_after_aug_preprocess.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Datapreprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check data types and missing values before removal\n",
    "print(\"Before removing nulls:\")\n",
    "print(df['instruction_augmented'].dtype)\n",
    "print(df['instruction_augmented'].isnull().sum())\n",
    "\n",
    "# Remove rows with null values in 'instruction_augmented' column\n",
    "df = df.dropna(subset=['instruction_augmented'])\n",
    "\n",
    "# Check data types and missing values after removal\n",
    "print(\"\\nAfter removing nulls:\")\n",
    "print(df['instruction_augmented'].dtype)\n",
    "print(df['instruction_augmented'].isnull().sum())\n",
    "\n",
    "\n",
    "# Now you can work with the 'data' DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Placeholder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Detect rows with placeholders\n",
    "df['has_placeholder'] = df['instruction_augmented'].str.contains(r'\\{\\{.*?\\}\\}')\n",
    "\n",
    "# Count rows with placeholders\n",
    "rows_with_placeholders = df['has_placeholder'].sum()\n",
    "\n",
    "# Extract placeholders function\n",
    "def extract_placeholders(text):\n",
    "    return re.findall(r'\\{\\{(.*?)\\}\\}', text)\n",
    "\n",
    "# Apply function and get all placeholders\n",
    "placeholders = df[df['has_placeholder']]['instruction_augmented'].apply(extract_placeholders).explode()\n",
    "\n",
    "# Count occurrences of each placeholder\n",
    "placeholder_counts = Counter(placeholders)\n",
    "\n",
    "# Convert to DataFrame (including frequency count)\n",
    "placeholder_df = pd.DataFrame(placeholder_counts.items(), columns=['placeholder', 'frequency'])\n",
    "\n",
    "# Sort by frequency in descending order\n",
    "placeholder_df = placeholder_df.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "# Display results\n",
    "print(f\"Rows with placeholders: {rows_with_placeholders}\")\n",
    "print(f\"Total unique placeholders: {len(placeholder_df)}\\n\")\n",
    "\n",
    "print(\"Distribution of Placeholders (Frequency Count):\")\n",
    "print(placeholder_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Fake Data For Placeholder and Saved Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Define synthetic data generators\n",
    "data_generators = {\n",
    "    'order number': lambda: fake.unique.bothify(text='ORD-#######'),\n",
    "    'invoice number': lambda: fake.unique.bothify(text='INV#####'),\n",
    "    'person name': lambda: fake.name(),\n",
    "    'account type': lambda: fake.random_element(elements=(\n",
    "        'Personal', 'Business', 'Corporate', 'Enterprise', 'VIP',\n",
    "        'Premium', 'Standard', 'Basic', 'Student', 'Non-Profit', 'Government'\n",
    "    )),\n",
    "    'account category': lambda: fake.random_element(elements=(\n",
    "        'Retail', 'E-commerce', 'Technology', 'Finance', 'Healthcare',\n",
    "        'Education', 'Real Estate', 'Hospitality', 'Manufacturing',\n",
    "        'Legal', 'Entertainment', 'Consulting', 'Logistics'\n",
    "    )),\n",
    "    'refund amount': lambda: f\"${fake.random_number(digits=3)}.00\",\n",
    "    'currency symbol': lambda: fake.currency_symbol(),\n",
    "    'delivery city': lambda: fake.city(),\n",
    "    'delivery country': lambda: fake.country()\n",
    "}\n",
    "\n",
    "# Function to replace placeholders and track NER labels\n",
    "def replace_placeholders(text, data_generators):\n",
    "    if pd.isnull(text):\n",
    "        return text, []  # Return empty list for NER labels\n",
    "\n",
    "    placeholder_pattern = re.compile(r'\\{\\{(.*?)\\}\\}')  # Match placeholders {{...}}\n",
    "    placeholders = placeholder_pattern.findall(text)\n",
    "    ner_labels = []  # Store entity labels\n",
    "\n",
    "    for placeholder in placeholders:\n",
    "        placeholder_cleaned = placeholder.strip().lower()  # Normalize case\n",
    "        if placeholder_cleaned in data_generators:\n",
    "            replacement_value = data_generators[placeholder_cleaned]()  # Generate synthetic data\n",
    "            text = text.replace(f'{{{{{placeholder}}}}}', replacement_value, 1)  # Replace placeholder\n",
    "\n",
    "            # Append entity info in required format\n",
    "            ner_labels.append({'text': replacement_value, 'label': placeholder_cleaned.replace(\" \", \"_\")})\n",
    "\n",
    "    return text, ner_labels\n",
    "\n",
    "# Apply the placeholder replacement function\n",
    "df[['instruction_augmented', 'ner_labels_only']] = df['instruction_augmented'].apply(\n",
    "    lambda x: pd.Series(replace_placeholders(x, data_generators))\n",
    ")\n",
    "\n",
    "# Ensure all rows are retained, even if ner_labels is empty\n",
    "df['ner_labels_only'] = df.apply(lambda row: row['ner_labels_only'] if row['has_placeholder'] else [], axis=1)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "df.to_csv(\"synthetic_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BIO Tags (FORMAT) and Tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('synthetic_data.csv')\n",
    "\n",
    "# Check data types and missing values before removal\n",
    "print(\"Before removing nulls:\")\n",
    "print(df['instruction_augmented'].dtype)\n",
    "print(df['instruction_augmented'].isnull().sum())\n",
    "\n",
    "# Remove rows with null values in 'instruction_augmented' column\n",
    "df = df.dropna(subset=['instruction_augmented'])\n",
    "\n",
    "# Check data types and missing values after removal\n",
    "print(\"\\nAfter removing nulls:\")\n",
    "print(df['instruction_augmented'].dtype)\n",
    "print(df['instruction_augmented'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert CSV TO JSON AND save FINAL DATA FOR TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"synthetic_data.csv\")\n",
    "\n",
    "# Ensure the `ner_labels_only` column is properly formatted as JSON\n",
    "def fix_json_format(value):\n",
    "    \"\"\"\n",
    "    Fix JSON formatting issues in the 'ner_labels_only' column.\n",
    "    Ensures it is a valid JSON string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If already valid JSON, return as is\n",
    "        if isinstance(value, str):\n",
    "            return json.loads(value.replace(\"'\", \"\\\"\"))  # Replace single quotes with double quotes\n",
    "    except json.JSONDecodeError:\n",
    "        pass  # If there's an error, leave it as is (optional: log the error)\n",
    "    return []  # Default to empty list if there's an issue\n",
    "\n",
    "# Apply formatting fix\n",
    "df[\"ner_labels_only\"] = df[\"ner_labels_only\"].apply(fix_json_format)\n",
    "\n",
    "# Save as JSON file\n",
    "df.to_json(\"fixed_dataset.json\", orient=\"records\", indent=4)\n",
    "\n",
    "print(\"CSV successfully converted to valid JSON format.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
