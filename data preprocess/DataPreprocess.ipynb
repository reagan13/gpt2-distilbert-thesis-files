{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (35.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#install': Expected package name at the start of dependency specifier\n",
      "    #install\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "%pip install faker\n",
    "%pip install easynmt #install package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: load dataset and drop the flags column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace 'your_dataset.csv' with the actual file name)\n",
    "data = pd.read_csv('../dataset/dataset.csv')\n",
    "\n",
    "# Drop the 'flags' column\n",
    "# data = data.drop('flags', axis=1)\n",
    "\n",
    "# Now you can work with the dataset without the 'flags' column\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = data[column].str.lower()\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: check missing values\n",
    "\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: drop missing values in the instruction_augmented column\n",
    "\n",
    "data = data.dropna(subset=['instruction_augmented'])\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category, Intent, NER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Check Distribution for 'intent' and 'category' columns\n",
    "print(\"Intent Distribution:\\n\", data['intent'].value_counts(normalize=True))\n",
    "print(\"\\nCategory Distribution:\\n\", data['category'].value_counts(normalize=True))\n",
    "\n",
    "# Plot Intent Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "data['intent'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Intent Distribution')\n",
    "plt.xlabel('Intent')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot Category Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "data['category'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Category Distribution')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Extract NER labels from the 'ner_labels_only' column\n",
    "ner_labels = [label['label'] for sublist in data['ner_labels_only'] if isinstance(sublist, list) for label in sublist if isinstance(label, dict)]\n",
    "ner_label_counts = Counter(ner_labels)\n",
    "print(\"\\nNER Label Counts:\")\n",
    "print(ner_label_counts)\n",
    "\n",
    "# Plot NER Label Counts\n",
    "if ner_label_counts:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    pd.Series(ner_label_counts).plot(kind='bar')\n",
    "    plt.title('NER Label Counts')\n",
    "    plt.xlabel('NER Label')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No NER labels found to plot.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation Distribution (for augmented dataset only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: check aug distribution based on the  augmentation_technique column and total counts of it also include the distribution in each intent\n",
    "\n",
    "# Check augmentation technique distribution\n",
    "aug_counts = data['augmentation_technique'].value_counts()\n",
    "print(\"\\nAugmentation Technique Distribution:\\n\", aug_counts)\n",
    "print(\"\\nAugmentation Technique Distribution (normalized):\\n\", aug_counts / len(data))\n",
    "\n",
    "# Check augmentation technique distribution per intent\n",
    "aug_intent_distribution = data.groupby(['intent', 'augmentation_technique']).size().unstack(fill_value=0)\n",
    "print(\"\\nAugmentation Technique Distribution per Intent:\\n\", aug_intent_distribution)\n",
    "\n",
    "# Calculate and display the distribution within each intent\n",
    "for intent in aug_intent_distribution.index:\n",
    "    intent_counts = aug_intent_distribution.loc[intent]\n",
    "    intent_distribution = intent_counts / intent_counts.sum()\n",
    "    print(f\"\\nDistribution for intent '{intent}':\\n{intent_distribution}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save to CSV\n",
    "data.to_csv(\"data_after_aug_preprocess.csv\", index=False)\n",
    "\n",
    "# Save to JSON Lines\n",
    "data.to_json(\"data_after_aug_preprocess.json\", orient=\"records\", lines=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
