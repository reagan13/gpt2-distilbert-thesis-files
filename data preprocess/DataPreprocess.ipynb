{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install faker\n",
    "%pip install easynmt #install package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: load dataset and drop the flags column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (replace 'your_dataset.csv' with the actual file name)\n",
    "data = pd.read_csv('augmented_dataset_v4.csv')\n",
    "\n",
    "# Drop the 'flags' column\n",
    "# data = data.drop('flags', axis=1)\n",
    "\n",
    "# Now you can work with the dataset without the 'flags' column\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = data[column].str.lower()\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: check missing values\n",
    "\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: drop missing values in the instruction_augmented column\n",
    "\n",
    "data = data.dropna(subset=['instruction_augmented'])\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove symbols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to clean the text\n",
    "\n",
    "def clean_text(text): # Remove unnecessary symbols except {{ }}\n",
    "cleaned_text = re.sub(r\"[^a-zA-Z0-9\\{\\}\\s]\", \"\", text)\n",
    "return cleaned_text\n",
    "data['instruction_augmented'] = data['instruction_augmented'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_placeholders(text):\n",
    "    # Find and clean placeholders\n",
    "    cleaned_text = re.sub(r'\\{\\{(.*?)\\}\\}', lambda m: \"{{\" + m.group(1).replace(\" uh \", \" \").replace(\" hmm \", \" \").replace(\" well \", \" \") + \"}}\", text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the cleaning function to the relevant column (e.g., 'instruction_augmented')\n",
    "data['instruction_augmented'] = data['instruction_augmented'].apply(clean_placeholders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category, Intent, NER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check Distribution for 'intent' and 'category' columns\n",
    "print(\"Intent Distribution:\\n\", data['intent'].value_counts(normalize=True))\n",
    "print(\"\\nCategory Distribution:\\n\", data['category'].value_counts(normalize=True))\n",
    "\n",
    "# Check for NER patterns in the 'instruction' column\n",
    "import re\n",
    "\n",
    "def find_ner_patterns(text):\n",
    "    pattern = r'\\{\\{(.*?)\\}\\}'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "data['ner_patterns'] = data['instruction_augmented'].apply(find_ner_patterns)\n",
    "\n",
    "# Display rows with found NER patterns\n",
    "# print(\"\\nNER Patterns in 'instruction' column:\")\n",
    "# print(data[data['ner_patterns'].apply(lambda x: len(x) > 0)])\n",
    "\n",
    "# You can further analyze the 'ner_patterns' column:\n",
    "# For example, count the occurrences of each NER pattern\n",
    "from collections import Counter\n",
    "\n",
    "all_ner_patterns = [item for sublist in data['ner_patterns'] for item in sublist]\n",
    "ner_pattern_counts = Counter(all_ner_patterns)\n",
    "print(\"\\nNER Pattern Counts:\")\n",
    "ner_pattern_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: check aug distribution based on the  augmentation_technique column and total counts of it also include the distribution in each intent\n",
    "\n",
    "# Check augmentation technique distribution\n",
    "aug_counts = data['augmentation_technique'].value_counts()\n",
    "print(\"\\nAugmentation Technique Distribution:\\n\", aug_counts)\n",
    "print(\"\\nAugmentation Technique Distribution (normalized):\\n\", aug_counts / len(data))\n",
    "\n",
    "# Check augmentation technique distribution per intent\n",
    "aug_intent_distribution = data.groupby(['intent', 'augmentation_technique']).size().unstack(fill_value=0)\n",
    "print(\"\\nAugmentation Technique Distribution per Intent:\\n\", aug_intent_distribution)\n",
    "\n",
    "# Calculate and display the distribution within each intent\n",
    "for intent in aug_intent_distribution.index:\n",
    "    intent_counts = aug_intent_distribution.loc[intent]\n",
    "    intent_distribution = intent_counts / intent_counts.sum()\n",
    "    print(f\"\\nDistribution for intent '{intent}':\\n{intent_distribution}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save to CSV\n",
    "data.to_csv(\"data_after_aug_preprocess.csv\", index=False)\n",
    "\n",
    "# Save to JSON Lines\n",
    "data.to_json(\"data_after_aug_preprocess.json\", orient=\"records\", lines=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
