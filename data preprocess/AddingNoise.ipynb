{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\reaga\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\reaga\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     flags                                        instruction category  \\\n",
      "4128   BLZ      i try to list your available payment methoids  payment   \n",
      "4129   BLZ  i nneed help to list the accepted payment methods  payment   \n",
      "4130  BILP  could you help me check what payment options a...  payment   \n",
      "4131   BLQ                             see ur payment methods  payment   \n",
      "4132   BCL  i have got to list the allowed payment modalit...  payment   \n",
      "\n",
      "                     intent  \\\n",
      "4128  check_payment_methods   \n",
      "4129  check_payment_methods   \n",
      "4130  check_payment_methods   \n",
      "4131  check_payment_methods   \n",
      "4132  check_payment_methods   \n",
      "\n",
      "                                               response  has_placeholder  \\\n",
      "4128  Of course! I appreciate your attempt to access...            False   \n",
      "4129  We really appreciate your inquiry and are more...            False   \n",
      "4130  We've received your message and requesting ass...            False   \n",
      "4131  I'll take care of it! I'm here to assist you i...            False   \n",
      "4132  Thank you for reaching out to us for assistanc...            False   \n",
      "\n",
      "     ner_labels_only                                             tokens  \\\n",
      "4128              []  ['i', 'try', 'to', 'list', 'your', 'available'...   \n",
      "4129              []  ['i', 'nneed', 'help', 'to', 'list', 'the', 'a...   \n",
      "4130              []  ['could', 'you', 'help', 'me', 'check', 'what'...   \n",
      "4131              []                ['see', 'ur', 'payment', 'methods']   \n",
      "4132              []  ['i', 'have', 'got', 'to', 'list', 'the', 'all...   \n",
      "\n",
      "                                                   tags  \n",
      "4128           ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']  \n",
      "4129      ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']  \n",
      "4130  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
      "4131                               ['O', 'O', 'O', 'O']  \n",
      "4132  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('./final_data_v1.csv')\n",
    "\n",
    "\n",
    "# Define the labels to remove\n",
    "labels_to_remove = [\n",
    "    'track_order', 'edit_account', 'track_refund', 'delivery_options', 'cancel_order',\n",
    "    'set_up_shipping_address', 'recover_password', 'contact_customer_service', 'contact_human_agent',\n",
    "    'check_refund_policy', 'change_shipping_address', 'check_cancellation_fee', 'get_refund',\n",
    "    'check_invoice', 'delete_account', 'get_invoice', 'create_account', 'change_order', 'switch_account'\n",
    "]\n",
    "\n",
    "# Remove rows with the specified labels in the 'intent' column\n",
    "df_cleaned = df[~df['intent'].isin(labels_to_remove)]\n",
    "\n",
    "# Save the cleaned DataFrame back to a CSV file\n",
    "df_cleaned.to_csv('drop_intent.csv', index=False)\n",
    "\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\reaga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\reaga\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete! Augmented dataset saved as 'augmented_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Function to get synonyms for a word\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)\n",
    "\n",
    "# Function to replace words with their synonyms\n",
    "def synonym_replacement(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if get_synonyms(word)]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) > 0:\n",
    "            synonym = random.choice(synonyms).replace(\"_\", \" \")\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n:\n",
    "            break\n",
    "\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "# Function to insert random words into the sentence\n",
    "def random_word_insertion(sentence, n=1):\n",
    "    words = sentence.split()\n",
    "    new_words = words.copy()\n",
    "\n",
    "    for _ in range(n):\n",
    "        random_word = random.choice(words)\n",
    "        random_idx = random.randint(0, len(new_words))\n",
    "        new_words.insert(random_idx, random_word)\n",
    "\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "# Function to delete random words from the sentence\n",
    "def random_word_deletion(sentence, p=0.1):\n",
    "    words = sentence.split()\n",
    "    new_words = [word for word in words if random.random() > p]\n",
    "    if len(new_words) == 0:  # Ensure we don't return an empty sentence\n",
    "        return sentence\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "# Main function to augment data\n",
    "def augment_data(df, augmentations_per_sentence=3):\n",
    "    augmented_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        instruction = row['instruction']\n",
    "        intent = row['intent']\n",
    "\n",
    "        # Apply synonym replacement\n",
    "        augmented_data.append({\n",
    "            'instruction': synonym_replacement(instruction),\n",
    "            'intent': intent\n",
    "        })\n",
    "\n",
    "        # Apply random word insertion\n",
    "        augmented_data.append({\n",
    "            'instruction': random_word_insertion(instruction),\n",
    "            'intent': intent\n",
    "        })\n",
    "\n",
    "        # Apply random word deletion\n",
    "        augmented_data.append({\n",
    "            'instruction': random_word_deletion(instruction),\n",
    "            'intent': intent\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(augmented_data)\n",
    "\n",
    "# Load your dataset\n",
    "csv_file = \"./drop_intent.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "\n",
    "# Augment the dataset\n",
    "augmented_df = augment_data(df)\n",
    "\n",
    "# Save the augmented dataset to a new CSV file\n",
    "augmented_df.to_csv(\"augmented_dataset1.csv\", index=False)\n",
    "\n",
    "print(\"Data augmentation complete! Augmented dataset saved as 'augmented_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23859\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "csv_file = \"augmented_dataset1.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
